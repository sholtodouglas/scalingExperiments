{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an exploration in strategies for scaling neural nets to _very large_ models across multiple devices. \n",
    "\n",
    "We'll start off by looking at the basic types of parallelism, then we might explore a more complex strategy which combines elements of the above, such as deepspeed!  \n",
    "\n",
    "- Data parallelism\n",
    "- Model parallelism\n",
    "- Pipeline parallelism\n",
    "- Tensor parallelism \n",
    "\n",
    "A note on hardware: In this notebook we'll use a TPU because the underlying hardware makes it much, much easier (if your needs scale, you can shift to larger and larger TPU pods without issues with inter-machine communication). Later on, we'll look at the classic approach (kubernetes clusters of individual devices) - but I believe in the long term most large model training will occur on mesh networks of devices (like TPUs, or Tesla's dojo). \n",
    "\n",
    "A couple of resources that I've leant on:\n",
    "\n",
    "- [This excellent series on deep learning hardware](https://blog.inten.to/hardware-for-deep-learning-current-state-and-trends-51c01ebbb6dc)\n",
    "- [Lilian Weng's superb notes on training large models](https://lilianweng.github.io/lil-log/2021/09/24/train-large-neural-networks.html)\n",
    "- [Ben Wang's GPT-J - to my knowledge the main published https://github.com/kingoflolz/mesh-transformer-jax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.profiler\n",
    "from jax import pmap,value_and_grad\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Let jax de-allocate memory when the object is no longer necessary, slows things down - but keeps our memory profiles accurate!\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR']='platform'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two helper functions which allow us to visualise memory usage\n",
    "\n",
    "def show_call_graph():\n",
    "    !go tool pprof -png memory.prof\n",
    "    img = Image.open('profile001.png')\n",
    "    os.remove('profile001.png')\n",
    "    return img\n",
    "\n",
    "def show_mem(result):\n",
    "    result.block_until_ready()\n",
    "    jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    !go tool pprof -tags memory.prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_devices = 8\n",
    "\n",
    "batch = 2048\n",
    "embed = 4096\n",
    "w_hidden = 8192\n",
    "\n",
    "keys = random.split(random.PRNGKey(0), x_devices) # [2,x_devices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple data parallel matrix multiplication\n",
    "\n",
    "- Lets use pmap to partition across each TPU node - easy!\n",
    "\n",
    "What are actually doing here? Our input is 8 batch 2048 vectors, each of dimension 4096 - in total we are doing 16384 examples, and multiplying them with a [4096, 8192] 'weights' matrix. \n",
    "\n",
    "There is an important distinction to call out here. In the first example, we pmap out and create 8 different weights matrices, so per device memory usage is the same. In the second, we first create a single large weights matrice to be distributed (that is [8, 4096, 8192]), which is implicitly created on jax.devices[0]. This means that the overall memory usage is the same, but most is concentrated on a single device - running a risk of running out of memory. We'll need to keep this in mind when doing model paralleism later - each shard of the model will have to be created separately on each device. If you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2048, 8192)\n",
      "\u001b[0;31mMain binary filename not available.\n",
      "\u001b[0m device: Total 1.8GB\n",
      "         224.0MB (12.50%): TPU_0(process=0,(0,0,0,0))\n",
      "         224.0MB (12.50%): TPU_1(process=0,(0,0,0,1))\n",
      "         224.0MB (12.50%): TPU_2(process=0,(1,0,0,0))\n",
      "         224.0MB (12.50%): TPU_3(process=0,(1,0,0,1))\n",
      "         224.0MB (12.50%): TPU_4(process=0,(0,1,0,0))\n",
      "         224.0MB (12.50%): TPU_5(process=0,(0,1,0,1))\n",
      "         224.0MB (12.50%): TPU_6(process=0,(1,1,0,0))\n",
      "         224.0MB (12.50%): TPU_7(process=0,(1,1,0,1))\n",
      "\n",
      " kind: Total 1.8GB\n",
      "         1.8GB (  100%): buffer\n",
      "       -9.0B (4.8e-07%): executable\n",
      "\n",
      "(8, 2048, 8192)\n",
      "\u001b[0;31mMain binary filename not available.\n",
      "\u001b[0m device: Total 1.9GB\n",
      "          1.2GB (65.00%): TPU_0(process=0,(0,0,0,0))\n",
      "         96.0MB ( 5.00%): TPU_1(process=0,(0,0,0,1))\n",
      "         96.0MB ( 5.00%): TPU_2(process=0,(1,0,0,0))\n",
      "         96.0MB ( 5.00%): TPU_3(process=0,(1,0,0,1))\n",
      "         96.0MB ( 5.00%): TPU_4(process=0,(0,1,0,0))\n",
      "         96.0MB ( 5.00%): TPU_5(process=0,(0,1,0,1))\n",
      "         96.0MB ( 5.00%): TPU_6(process=0,(1,1,0,0))\n",
      "         96.0MB ( 5.00%): TPU_7(process=0,(1,1,0,1))\n",
      "\n",
      " kind: Total 1.9GB\n",
      "        1.9GB (  100%): buffer\n",
      "       -14.0B (7e-07%): executable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def matmult(inp,w1):\n",
    "    # run a local matmul on each device in parallel (no data transfer)\n",
    "    result = pmap(jnp.matmul)(inp,w1)\n",
    "    print(result.shape)\n",
    "    show_mem(result)\n",
    "\n",
    "inp = pmap(lambda key: random.normal(key, (batch, embed), dtype=jnp.float32))(keys) # [x_devices, batch, embed]\n",
    "w1  = pmap(lambda key: random.normal(key, (embed, w_hidden), dtype=jnp.float32))(keys) # [w_hidden, embed]\n",
    "\n",
    "matmult(inp, w1)\n",
    "\n",
    "\n",
    "inp = pmap(lambda key: random.normal(key, (batch, embed), dtype=jnp.float32))(keys) # [x_devices, batch, embed]\n",
    "w1  = random.normal(random.PRNGKey(0), (w_hidden, embed), dtype=jnp.float32) # [w_hidden, embed]\n",
    "w1_dist = jnp.stack([w1.T] * x_devices) # create a copy to be pmapped across each device\n",
    "\n",
    "matmult(inp, w1_dist)\n",
    "\n",
    "del w1_dist # gc this so that it doesn't clog up memory if the cell is re-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do gradients affect memory usage?\n",
    "\n",
    "- As we can see, taking gradients w.r.t the input matrix effectively doubles memory usage - this makes sense! We're taking gradients w.r.t to both the input and the weight here and need to store them on the device with a 1:1 parameter ratio - so the only thing not doubled is the final output. \n",
    "\n",
    "- The gradients will turn out to be extremely important - optimizers like ADAM keep multiple states per paramter for the momentum calculation. Optimising this is one of the critical improvements made by DeepSpeed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mMain binary filename not available.\r",
      "\r\n",
      "\u001b[0m device: Total 1.5GB\r\n",
      "         192.0MB (12.50%): TPU_0(process=0,(0,0,0,0))\r\n",
      "         192.0MB (12.50%): TPU_1(process=0,(0,0,0,1))\r\n",
      "         192.0MB (12.50%): TPU_2(process=0,(1,0,0,0))\r\n",
      "         192.0MB (12.50%): TPU_3(process=0,(1,0,0,1))\r\n",
      "         192.0MB (12.50%): TPU_4(process=0,(0,1,0,0))\r\n",
      "         192.0MB (12.50%): TPU_5(process=0,(0,1,0,1))\r\n",
      "         192.0MB (12.50%): TPU_6(process=0,(1,1,0,0))\r\n",
      "         192.0MB (12.50%): TPU_7(process=0,(1,1,0,1))\r\n",
      "\r\n",
      " kind: Total 1.5GB\r\n",
      "          1.5GB (  100%): buffer\r\n",
      "       -14.0B (8.7e-07%): executable\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "def matmult_and_grad(inp,w1, devices=8):\n",
    "    # run a local matmul on each device in parallel (no data transfer)\n",
    "    def matmul_and_mean(inp, w1):\n",
    "        result = jnp.mean(jnp.matmul(inp,w1))\n",
    "        return result\n",
    "        \n",
    "    # notice, we take the gradients w.r.t to all of them on a single TPU here. Interesting!\n",
    "    value, grad = pmap(value_and_grad(matmul_and_mean))(inp, w1)\n",
    "    \n",
    "    show_mem(grad)\n",
    "    \n",
    "inp = pmap(lambda key: random.normal(key, (batch, embed), dtype=jnp.float32))(keys) # [x_devices, batch, embed]\n",
    "w1  = pmap(lambda key: random.normal(key, (embed, w_hidden), dtype=jnp.float32))(keys) # [w_hidden, embed]\n",
    "matmult_and_grad(inp, w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor parallelism\n",
    "\n",
    "What if we have a layer or model that is too big to fit on a single device? \n",
    "\n",
    "The great thing about TPUs is that they are a hardware _mesh_ - and when we use xmap we can use named axis to re-arrange these at will to achieve both data and model parallelism.\n",
    "\n",
    "How does model parallelism work? For starters, lets look at [Megatron LM's method](https://arxiv.org/pdf/1909.08053.pdf), which is what was used for GPT-J. It has a great balance of simplicity and effectiveness, and is very efficient provided you have a hardware mesh. Luckily we do!\n",
    "\n",
    "- Megatron LM: Takes advantage of the fact that sections of a matrix multiplication and self-attention can be calculated across separate devices with minimal communication. Megatron's approach optimises for minimising communication overheads at the expense of some increase in memory. E.g., the layer norm parameters are duplicated, and take the output of the previous layer. \"Since all parameters are either local or duplicated, there is no need for communicating updated parameters.\"\n",
    "\n",
    "How does it work in the case of a simple matrix multiplication + nonlinearity?\n",
    "\n",
    "$$ Y  = GELU(XA) $$ \n",
    "\n",
    "If we split A along it's columns A = [A_1, A_2], we can perform the calculation and apply the non-linearity indepedently.\n",
    "\n",
    "$$ Y  = [Y_1, Y_2] = [GeLU(XA_1), GeLU(XA_2)]$$\n",
    "\n",
    "In the next section we'll look at how it works with multiple MMs and self-attention, first lets introduce x-map!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.maps import mesh, xmap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16384\n",
    "embed = 4096\n",
    "w_hidden = 8192\n",
    "\n",
    "inp = random.normal(random.PRNGKey(0), (batch, embed), dtype=jnp.float32) # [batch, embed]\n",
    "w1  = random.normal(random.PRNGKey(0), (w_hidden, embed), dtype=jnp.float32) # [w_hidden, embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape our 8 devices into a 2,4 mesh with axis names x,y\n",
    "\n",
    "x_devices = 4\n",
    "y_devices = 8//x_devices\n",
    "\n",
    "axis_names = ('x', 'y')\n",
    "mesh_devices = np.array(jax.devices()).reshape((x_devices, y_devices))\n",
    "mesh_def = (mesh_devices, axis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/jax/experimental/maps.py:418: UserWarning: xmap is an experimental feature and probably has bugs!\n",
      "  warn(\"xmap is an experimental feature and probably has bugs!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mMain binary filename not available.\n",
      "\u001b[0m device: Total 896.0MB\n",
      "         448.0MB (50.00%): TPU_0(process=0,(0,0,0,0))\n",
      "          64.0MB ( 7.14%): TPU_1(process=0,(0,0,0,1))\n",
      "          64.0MB ( 7.14%): TPU_2(process=0,(1,0,0,0))\n",
      "          64.0MB ( 7.14%): TPU_3(process=0,(1,0,0,1))\n",
      "          64.0MB ( 7.14%): TPU_4(process=0,(0,1,0,0))\n",
      "          64.0MB ( 7.14%): TPU_5(process=0,(0,1,0,1))\n",
      "          64.0MB ( 7.14%): TPU_6(process=0,(1,1,0,0))\n",
      "          64.0MB ( 7.14%): TPU_7(process=0,(1,1,0,1))\n",
      "\n",
      " kind: Total 896.0MB\n",
      "        896.0MB (  100%): buffer\n",
      "       -18.0B (1.9e-06%): executable\n",
      "\n",
      "(16384, 8192)\n"
     ]
    }
   ],
   "source": [
    "def matmult(x, w1):\n",
    "    '''\n",
    "    x: [x_devices: the number of devices we are partitioning across\n",
    "        batch: ..\n",
    "        embed: .. ]\n",
    "    w1: [w_hidden: will be partioned evenly over the columns of the mesh \n",
    "         embed: the hidden size, but it is partitioned ... ]\n",
    "    '''\n",
    "\n",
    "    res = jnp.matmul(x,w1)\n",
    "    mean_embed = jnp.sum(res, axis=['batch']) / 8096\n",
    "    return mean_embed\n",
    "\n",
    "with mesh(*mesh_def):\n",
    "    out = xmap(matmult, \n",
    "              in_axes = (['batch',  ...], ['w_hidden', ...]),\n",
    "              out_axes = ['batch', 'w_hidden', ...],\n",
    "              axis_resources={'batch': 'x', 'w_hidden': 'y'})(inp, w1)\n",
    "    \n",
    "    \n",
    "    show_mem(out)\n",
    "    print(out.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really cool! With x-map, we can just take the same size inputs [16384, 4096] and [4096, 8192], and perform the computation in both a data and batch parallel fashion. The batch axis is split across 4 machines, the weight across 2. Now - the issue is that like the second example these large matrices were created on device 0 and remain there. Lets do this properly this time, and start building the components for a transformer block.  We'll need to init the component of the weights separately across each 'shard'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A transformer block\n",
    "\n",
    "- Ben Wang's GPT-J has an excellent, production ready example. Here, we'll draw from the design choices of both minGPT and GPT-J in an effort to make a minimal, but complete example. The biggest difference you'll notice is the absence of the batch dimension inside the block. When I wrote this initially I did it much closer to the minGPT implementation (e.g. 'bhtT, bThd->bthd'), but if you partition the batch dimension across one of the dimensions in your hardware mesh it gets abstracted away - and so the internal code is very similar to GPT-J. \n",
    "- The key fact that we're taking advantage of is that sections of the embedding are allocated to differnet self-attention 'heads' - which means that we can split across shards easily. So long as the # heads is divisible by the number of shards. E.g. if our embedding is 2048, and we have 8 heads of 256 each - we could split the embedding across 2 shards, alllocating 4 heads per shard. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "\n",
    "# A simple transformer layer shard that exists on one of the devices. \n",
    "\n",
    "\n",
    "GPT1Config = {\n",
    "    'n_vocab': 5000,\n",
    "    'block_size': 32,\n",
    "    'n_layer' : 12,\n",
    "    'n_head' : 12,\n",
    "    'd_model' : 768,\n",
    "    'shards': 2}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TransformerLayerShard(hk.Module):\n",
    "        def __init__(self, config, name=None, init_scale=1.):\n",
    "            super().__init__(name=name)\n",
    "            heads = config[\"n_head\"]\n",
    "            dim = config[\"d_model\"]\n",
    "            self.shards  = config[\"shards\"]\n",
    "            \n",
    "            assert dim % heads == 0 \n",
    "            assert heads % self.shards == 0 \n",
    "            \n",
    "            self.dim_per_head = dim // heads\n",
    "            self.dim_per_shard = dim // self.shards\n",
    "            self.heads_per_shard = heads // self.shards\n",
    "#             print(self.dim_per_head, self.dim_per_shard, self.heads_per_shard)\n",
    "            \n",
    "            # GPT-J uses a common layer norm between the mlp and the self attention, minGPT uses different - lets go with one for now. Much of a muchness.\n",
    "            self.ln = hk.LayerNorm(-1, True, True)\n",
    "            \n",
    "            # key, query and value projections for all heads on this shard\n",
    "            self.q = hk.Linear(self.dim_per_shard, with_bias=False)\n",
    "            self.k = hk.Linear(self.dim_per_shard, with_bias=False)\n",
    "            self.v = hk.Linear(self.dim_per_shard, with_bias=False)\n",
    "            \n",
    "            # self att output projection\n",
    "            self.att_proj = hk.Linear(dim, with_bias=False, w_init=hk.initializers.TruncatedNormal(stddev=init_scale / np.sqrt(dim)))\n",
    "            \n",
    "            self.dense_proj = hk.Linear(self.dim_per_shard * 4)\n",
    "            self.dense_proj_out = hk.Linear(dim,\n",
    "                                      w_init=hk.initializers.TruncatedNormal(stddev=init_scale / np.sqrt(dim)))\n",
    "            \n",
    "            \n",
    "        def self_attention(self, q, k ,v, bias):\n",
    "            '''\n",
    "            k,q,v: [T, heads_per_shard, dim_per_head]\n",
    "            '''\n",
    "            T, _, _ = k.shape\n",
    "            \n",
    "            attention_logits = jnp.einsum('thd,Thd->htT', q, k) # [heads_per_shard, T,T]\n",
    "            sqrt_key_size = np.sqrt(self.dim_per_head).astype(k.dtype) # [1,]\n",
    "            \n",
    "            attention_logits = attention_logits/sqrt_key_size # [heads_per_shard, T,T]\n",
    "            \n",
    "            attention_logits += bias # [B, heads_per_shard, T,T]\n",
    "            \n",
    "            attention_weights = jax.nn.softmax(attention_logits)  # [heads_per_shard, T,T]\n",
    "            \n",
    "            weighted_values = jnp.einsum('htT, Thd->thd', attention_weights, v).reshape((T, self.dim_per_shard)) # [T, dim_per_shard]\n",
    "            \n",
    "            return self.att_proj(weighted_values)\n",
    "        \n",
    "        def feed_forward(self, x):\n",
    "            '''\n",
    "            x: [T,embed_dim]\n",
    "            '''\n",
    "            dense_proj = self.dense_proj(x)\n",
    "            dense_proj = jax.nn.gelu(dense_proj)\n",
    "            return self.dense_proj_out(dense_proj)\n",
    "            \n",
    "            \n",
    "        def qkv_proj(self, x): \n",
    "            '''\n",
    "            x: [T, embed_dim]\n",
    "            '''\n",
    "            q = self.q(x).reshape(x.shape[:-1] + (self.heads_per_shard, self.dim_per_head)) # [T, heads_per_shard, dim_per_head]\n",
    "            v = self.v(x).reshape(x.shape[:-1] + (self.heads_per_shard, self.dim_per_head)) # \"\"\n",
    "            k = self.k(x).reshape(x.shape[:-1] + (self.heads_per_shard, self.dim_per_head)) # \"\" \n",
    "            \n",
    "            return q,k,v\n",
    "        \n",
    "        \n",
    "        def __call__(self, x):\n",
    "            '''\n",
    "            x: [T, embed_dim]\n",
    "            '''\n",
    "            # preliminaries    \n",
    "#             print(x.shape)\n",
    "            T,C = x.shape\n",
    "            x = self.ln(x) # [T,embed_dim]\n",
    "            \n",
    "            # causal self attention\n",
    "            q,k,v = self.qkv_proj(x)\n",
    "            causal_mask = np.tril(np.ones((T,T))) # [T,T]\n",
    "            bias = -1e10 * (1. - causal_mask) # [T,T]\n",
    "            attn = self.self_attention(q, k ,v, bias)  # [T,embed_dim]\n",
    "            \n",
    "            # feedforward\n",
    "            ff  = self.feed_forward(x) # [B,T,embed_dim]\n",
    "            \n",
    "            # block\n",
    "            x = x + attn # [T,embed_dim]\n",
    "            x = x + ff # [T,embed_dim]\n",
    "            \n",
    "            # We finally need to sum across shards to collect the information from each head into the new embedding \n",
    "            # In the full GPT-J implementation, they've defined a custom operator which does the psum on the forward pass but\n",
    "            # is the identity function on the backward pass - currently testing how necessary that is.\n",
    "            return jax.lax.psum(x, \"shard\")\n",
    "\n",
    "        \n",
    "                \n",
    "def model_fn(x):\n",
    "    model = TransformerLayerShard(GPT1Config)\n",
    "    return model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be possible to test the above block without xmap if we got rid of the psum - but I'm going to be slightly opinionated here despite the boilerplate setup.\n",
    "\n",
    "\n",
    "batch = 4\n",
    "shard = 2\n",
    "\n",
    "axis_names = ('dp', 'mp')\n",
    "mesh_devices = np.array(jax.devices()).reshape((batch, shard))\n",
    "mesh_def = (mesh_devices, axis_names)\n",
    "\n",
    "\n",
    "init = jax.experimental.maps.xmap(fun=hk.transform(model_fn).init,\n",
    "                                  in_axes=([\"shard\", ...],\n",
    "                                           [\"batch\", ...]),\n",
    "                                  out_axes=[\"shard\", ...],\n",
    "                                  axis_resources={'shard': 'mp', 'batch': 'dp'})\n",
    "\n",
    "forward = jax.experimental.maps.xmap(fun=hk.without_apply_rng(hk.transform(model_fn)).apply,\n",
    "                                     in_axes=([\"shard\", ...],\n",
    "                                              [\"batch\", ...]),\n",
    "                                     out_axes=[\"batch\", ...],\n",
    "                                     axis_resources={'shard': 'mp', 'batch': 'dp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 32, 768)\n"
     ]
    }
   ],
   "source": [
    "key = hk.PRNGSequence(42)\n",
    "x = jax.random.uniform(next(key), (16, 32, 768), minval=0, maxval=255).astype(jnp.float32)  # [B,T,embed]\n",
    "\n",
    "with jax.experimental.maps.mesh(*mesh_def):\n",
    "    state = init(jnp.array(key.take(shard)), x)\n",
    "\n",
    "    o = forward(state, x)\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a transformer\n",
    "\n",
    "Now all we're missing is an embedding layer to transform a sequence of discrete tokens to a dense vector - and an output projection layer to send it back! \n",
    "\n",
    "\n",
    "## Embedding layer\n",
    "Functionally, this is a sequence of [Batch, Time, Vocab_size] multiplied by a [Vocab_size, embedding_dim] matrix to project the one hot sequence into a dense embedding. \n",
    "\n",
    "There are two approaches that could make sense:\n",
    "\n",
    "1. Partition the embedding matrix along the vocabulary dimension. The implementation of this in GPT-J is cheeky:\n",
    "    i. Assign a subset of token indices to each shard. E.g. if our vocab dimension is 50k, 0-25k correspond to shard 0, 25k-50k correspond to shard 1.\n",
    "    ii. In the one-hot expansion of the input sequence, zero anything which lies outside this range. This means that the projection matrix on each shard only needs to be [25k,embedding_dim], but the zero-d tokens will not contribute to the embedding on that shard.\n",
    "    iii. psum across the shards to get the full embedding. \n",
    "    \n",
    "    \n",
    "2. Alternatively, partition along the embedding dimension. In this case, the embedding matrix on each shard would be [50k, embedding_dim//shards], every token would be fully expanded into the one-hot representation and an all_gather would be required across the shards to concatenate the embedding dim of the outputs.\n",
    "\n",
    "In both cases  <b> the embedding weights matrix will be the same size  </b> (it doesn't matter which dimension is divided by shards),  <b> but the methods differ in terms of the space allocated for the input sequence</b>. The second method requires the full input sequence be expanded to the full one-hot representation on each device, but the first method divides the size of that representation by the number of shards - saving more space. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingShard(hk.Module):\n",
    "    def __init__(self, config, name=None):\n",
    "        super().__init__(name=name)\n",
    "        in_dim = config[\"n_vocab\"]\n",
    "        out_dim = config[\"d_model\"]\n",
    "        shards = config[\"shards\"]\n",
    "\n",
    "        assert in_dim % shards == 0\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim_per_shard = in_dim // shards\n",
    "        self.out_dim_per_shard = out_dim // shards\n",
    "\n",
    "        embed_init = hk.initializers.TruncatedNormal(stddev=0.02)\n",
    "        self.positional_embeddings = hk.get_parameter('pos_embs', [config[\"block_size\"], self.out_dim_per_shard], init=embed_init)\n",
    "\n",
    "        # notice unlike the ff transformer layer, this linear layer has the full output dimension because we are partitioning across vocab. \n",
    "        self.proj = hk.Linear(self.out_dim, w_init=hk.initializers.TruncatedNormal(stddev=1 / np.sqrt(in_dim)))\n",
    "\n",
    "    def __call__(self, x, dtype=jnp.bfloat16):\n",
    "        \n",
    "        # work out which shard we are on, and the start token index\n",
    "        shard_start_index = jax.lax.axis_index('shard') * self.in_dim_per_shard\n",
    "        \n",
    "        # subtract the shard_start_index from the input indices. This means anything below it will be zero-d (as it will be a negative number)\n",
    "        # at the same time, anything above 'in_dim_per_shard' will also be zero-d. This means that each shard gets a window of in_dim_per_shard indices\n",
    "        # which it will expand to a one-hot representation - saving lots of space!\n",
    "        input_onehot = jax.nn.one_hot(x - shard_start_index, self.in_dim_per_shard)\n",
    "        proj_out = self.proj(input_onehot)\n",
    "        # sum across shards to create a full embedding\n",
    "        proj_out = jax.lax.psum(proj_out, \"shard\")\n",
    "        # gets all of the positional embeddings as split across each shard (column wise split of positional embeddings)\n",
    "        all_pos_embed = jax.lax.all_gather(self.positional_embeddings, 'shard')\n",
    "        # flattens them, so now there are identical, complete positional embeddings on each device\n",
    "        all_pos_embed = hk.Flatten()(jnp.transpose(all_pos_embed, (1, 0, 2)))\n",
    "\n",
    "        proj_out += all_pos_embed[:proj_out.shape[0]] # only do the embeddings up to the length of the input sequence, to allow for variable input size\n",
    "\n",
    "        return proj_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection layer\n",
    "\n",
    "The projection layer is much more similar to the simple matrix multiplication example above. As we'll have the full embedding as an output of transformer layer below we partition across the output dim, then all gather to get the final output embedding in vocab space. \n",
    "\n",
    "Where it gets trickier is how this interacts with the loss calculation. The [batch, time, vocab_size] matrix output above is large, and we'd prefer to only generate it when necesary (e.g. during inference). During training, could we calculate the per shard loss components and then only cross-communicate the smaller [batch, time] cross entropy loss values?\n",
    "\n",
    "Yes! We'll still need some cross communication (e.g. to calculate the max of the logits to stabilise it numerically, or calculate the denominator of the softmax equation), but this comes with no memory penalty!\n",
    "\n",
    "This is directly lifted from GPT-J, but I'll comment extensively so it is clear what is going on.\n",
    "\n",
    "The loss function isn't the typical implementation of softmax cross entropy, so lets simplify it down to explain it. The implementation is convenient and stable - minimising communication overheads across shards to a limited set of sums. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3  0.  -0. ]\n",
      " [-0.   0.  -1.6]]\n",
      "3.719463\n",
      "[[ 0.         -0.         -0.        ]\n",
      " [-0.          0.         -0.00945294]]\n",
      "1.6977012\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.8638048\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.5450409\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.39282578\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.30563444\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.24965373\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.21083269\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.18234465\n",
      "[[ 0. -0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "0.16059524\n"
     ]
    }
   ],
   "source": [
    "# A test case\n",
    "logit = jnp.array([[-0.3,1,0.1], [0.1, 2, 0.4]])\n",
    "target = jnp.array([[1,0,0], [0,0,1]])\n",
    "\n",
    "def loss(logit, target):\n",
    "    # numerically stabilise logits\n",
    "    stable_logit = logit - logit.max(-1, keepdims=True)\n",
    "    # zero out any entries in the logit which don't correspond to the true label\n",
    "    predicted_logit = jnp.multiply(target, stable_logit)\n",
    "    # sum up the logit\n",
    "    log_sum_exp = jnp.log(jnp.exp(stable_logit).sum(axis=-1))\n",
    "    # subtract the summed logit from the summed 'predicted_logit'\n",
    "    # On a per dimension basis, if the maximum value is in the correct entry\n",
    "    # then the subtraction will = 0. Similarly, any entry but the correct one is 0 in the label.\n",
    "    # therefore the element wise multiplication of the stable logit with the target which converges because\n",
    "    # logit is on both the LHS and RHS of the equation. \n",
    "    # By only working with sums when we are using the sharded version we minimise communication.\n",
    "    loss = log_sum_exp - predicted_logit.sum(axis=-1)\n",
    "    # And it allows for a really elegant way of calculating accuracy!\n",
    "    return loss.sum()\n",
    "    \n",
    "\n",
    "for i in range(0,10):\n",
    "    print(jnp.multiply(target, logit - logit.max(-1, keepdims=True)))\n",
    "    l, grad_wrt_logit  =  value_and_grad(loss)(logit, target)\n",
    "    logit -= 1 * grad_wrt_logit\n",
    "    print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class ProjectionShard(hk.Module):\n",
    "    def __init__(self, config, name=None):\n",
    "        super().__init__(name=name)\n",
    "        out_dim = config[\"n_vocab\"]\n",
    "        shards = config[\"shards\"]\n",
    "\n",
    "        assert out_dim % shards == 0\n",
    "\n",
    "        self.dim = out_dim\n",
    "        self.dim_per_shard = out_dim // shards\n",
    "\n",
    "        self.norm = hk.LayerNorm(-1, True, True)\n",
    "\n",
    "        self.proj = hk.Linear(self.dim_per_shard)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.norm(x)\n",
    "        proj = self.proj(x)\n",
    "\n",
    "        all_proj = jax.lax.all_gather(proj, 'shard')\n",
    "\n",
    "        return hk.Flatten()(jnp.transpose(all_proj, (1, 0, 2)))\n",
    "\n",
    "    def loss(self, x, targets, z_loss=1):\n",
    "        \n",
    "        '''\n",
    "        x: [T, dim_per_shard]\n",
    "        targets: [T]\n",
    "        '''\n",
    "        x = self.norm(x)\n",
    "        # calculate logits on a per shard basis\n",
    "        logits = self.proj(x) # [T, dim_per_shard]\n",
    "        # get the max of logits per dimension across the shards. Use this to prevent both under and overflow by subtracting it from every logit.\n",
    "        # For an explaination on why you need this - see the opening pages of chapter 4 'Numerical computation' in goodfellow's deep learning book. \n",
    "        global_max = jax.lax.pmax(jax.lax.stop_gradient(logits.max(-1, keepdims=True)), \"shard\")\n",
    "        logits -= jax.lax.stop_gradient(global_max) # [T, dim_per_shard]\n",
    "        \n",
    "        # As we are computing the output vocab matrix in a sharded fashion, only get the targets corresponding to that shard\n",
    "        # using the same trick as used in the embedding matrix.\n",
    "        shard_start_index = jax.lax.axis_index('shard') * self.dim_per_shard\n",
    "        gt_onehot = jax.nn.one_hot(targets - shard_start_index, self.dim_per_shard) # [T, dim_per_shard]\n",
    "        # this is a point multiplication, so it zeros out anything which isn't a 1 in the one-hot representation. \n",
    "        # then sums along the embedding axis. See above code snippet for explaination for the next few lines.\n",
    "        predicted_logits = jnp.sum(jnp.multiply(gt_onehot, logits), axis=-1) # [T]\n",
    "        predicted_logits = jax.lax.psum(predicted_logits, 'shard') \n",
    "        exp_logits = jnp.exp(logits)\n",
    "        sum_exp_logits = exp_logits.sum(axis=-1)\n",
    "        sum_exp_logits = jax.lax.psum(sum_exp_logits, 'shard')\n",
    "\n",
    "        loss = jnp.log(sum_exp_logits) - predicted_logits\n",
    "        # An additional loss which keeps the logits small - avoiding roundoff errors in bfloat16 (according to the mesh tensorflow repo).\n",
    "        loss += (1e-4 * jnp.square(jnp.log(sum_exp_logits)) * z_loss).mean()\n",
    "\n",
    "        correct = (0.0 == predicted_logits)\n",
    "        return loss.sum(), correct\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharded transformer\n",
    "\n",
    "This is easy - just combine the sharded layers as one would a transformer on one device. Saving and loading weights will be a little more complex though :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTransformerShard(hk.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        heads = config[\"n_head\"]\n",
    "        shards = config[\"shards\"]\n",
    "        layer_count = config[\"n_layer\"]\n",
    "\n",
    "        self.layers = []\n",
    "        self.heads = heads\n",
    "\n",
    "        self.heads_per_shard = heads // shards\n",
    "\n",
    "        self.embed = EmbeddingShard(config)\n",
    "\n",
    "        init_scale = 2. / layer_count\n",
    "\n",
    "        for i in range(layer_count):\n",
    "            self.layers.append(TransformerLayerShard(config, name=f\"layer_{i}\", init_scale=init_scale))\n",
    "\n",
    "        self.proj = ProjectionShard(config)\n",
    "        \n",
    "        \n",
    "    def trunk(self, tokens):\n",
    "        x = self.embed(tokens)\n",
    "\n",
    "        for l in self.layers:\n",
    "            x = x + l(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, tokens, targets):\n",
    "        x = self.trunk(tokens)\n",
    "        l, acc = self.proj.loss(x, targets)\n",
    "        return l\n",
    "\n",
    "    def __call__(self, tokens):\n",
    "        \n",
    "        x = self.trunk(tokens)\n",
    "        return self.proj(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/jax/experimental/maps.py:418: UserWarning: xmap is an experimental feature and probably has bugs!\n",
      "  warn(\"xmap is an experimental feature and probably has bugs!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mMain binary filename not available.\r",
      "\r\n",
      "\u001b[0m device: Total 23.9GB\r\n",
      "         3.3GB (13.87%): TPU_0(process=0,(0,0,0,0))\r\n",
      "         2.9GB (12.30%): TPU_1(process=0,(0,0,0,1))\r\n",
      "         2.9GB (12.30%): TPU_2(process=0,(1,0,0,0))\r\n",
      "         2.9GB (12.30%): TPU_3(process=0,(1,0,0,1))\r\n",
      "         2.9GB (12.30%): TPU_4(process=0,(0,1,0,0))\r\n",
      "         2.9GB (12.30%): TPU_5(process=0,(0,1,0,1))\r\n",
      "         2.9GB (12.30%): TPU_6(process=0,(1,1,0,0))\r\n",
      "         2.9GB (12.30%): TPU_7(process=0,(1,1,0,1))\r\n",
      "\r\n",
      " kind: Total 23.9GB\r\n",
      "         23.9GB (  100%): buffer\r\n",
      "       -54.0B (2.1e-07%): executable\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "\n",
    "batch = 4\n",
    "shard = 2\n",
    "\n",
    "GPT1Config = {\n",
    "    'n_vocab': 5000,\n",
    "    'block_size': 32,\n",
    "    'n_layer' : 2,\n",
    "    'n_head' : 4,\n",
    "    'd_model' : 768*4,\n",
    "    'shards': 2}\n",
    "\n",
    "\n",
    "\n",
    "axis_names = ('batch', 'shard')\n",
    "mesh_devices = np.array(jax.devices()).reshape((batch, shard))\n",
    "mesh_def = (mesh_devices, axis_names)\n",
    "\n",
    "\n",
    "optimizer = optax.adam(1e-5)\n",
    "\n",
    "# Haiku pure functions for convenience \n",
    "def eval_fn(x):\n",
    "    model = CausalTransformerShard(GPT1Config)\n",
    "    return model(x)\n",
    "\n",
    "def train_fn(x,y):\n",
    "    model = CausalTransformerShard(GPT1Config)\n",
    "    return model.loss(x,y)\n",
    "\n",
    "\n",
    "def init(key, x):\n",
    "    '''\n",
    "    A parallelised init function that ensures optimiser params are stored on the respective devices. \n",
    "    '''\n",
    "    params = hk.transform(eval_fn).init(key, x)\n",
    "    \n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"step\": np.array(0),\n",
    "        \"opt_state\": optimizer.init(params)\n",
    "    }\n",
    "\n",
    "def eval_step(params, x):\n",
    "    \n",
    "    forward_fn = hk.without_apply_rng(hk.transform(eval_fn))\n",
    "    out = forward_fn.apply(params, x)\n",
    "    return out\n",
    "\n",
    "def train_step(state, x,y):\n",
    "    \n",
    "    l_fn = hk.without_apply_rng(hk.transform(train_fn))\n",
    "    loss, grads = value_and_grad(l_fn.apply)(state['params'], x,y)\n",
    "    grads = jax.lax.pmean(grads, \"batch\")\n",
    "    updates, new_opt_state = optimizer.update(grads, state['opt_state'], state['params'])\n",
    "    \n",
    "    return loss, {\n",
    "        \"params\": optax.apply_updates(state['params'], updates),\n",
    "        \"step\": state['step'] + 1,\n",
    "        \"opt_state\": new_opt_state\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "init = jax.experimental.maps.xmap(fun=init,\n",
    "                                  in_axes=([\"shard\", ...], # rngs\n",
    "                                           [\"batch\", ...]), # x\n",
    "                                  out_axes=[\"shard\", ...],\n",
    "                                  axis_resources={'shard': 'shard', 'batch': 'batch'})\n",
    "\n",
    "forward = jax.experimental.maps.xmap(fun=eval_step,\n",
    "                                     in_axes=([\"shard\", ...], # params\n",
    "                                              [\"batch\", ...]), # x \n",
    "                                     out_axes=([\"batch\", ...]), \n",
    "                                     axis_resources={'shard': 'shard', 'batch': 'batch'})\n",
    "\n",
    "\n",
    "train = jax.experimental.maps.xmap(fun=train_step,\n",
    "                                     in_axes=([\"shard\", ...], # state\n",
    "                                              [\"batch\", ...], # x\n",
    "                                              [\"batch\", ...]),# y\n",
    "                                     out_axes=([['batch'],           # loss\n",
    "                                               ['shard',...]]), # state\n",
    "                                     axis_resources={'shard': 'shard', 'batch': 'batch'})\n",
    "\n",
    "key = hk.PRNGSequence(42)\n",
    "# x = jax.random.uniform(next(key), (16, 32), minval=0, maxval=255).astype(jnp.int32)  # [B,T,embed]\n",
    "\n",
    "with jax.experimental.maps.mesh(*mesh_def):\n",
    "    state = init(jnp.array(key.take(shard)), x)\n",
    "\n",
    "    o = forward(state['params'], x)\n",
    "    show_mem(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09622939\n"
     ]
    }
   ],
   "source": [
    "with jax.experimental.maps.mesh(*mesh_def):\n",
    "    loss, state = train(state, x,x)\n",
    "    print(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ShardedDeviceArray([9, 9], dtype=int32),\n",
       "  ShardedDeviceArray([[[-0.14311841, -0.02470583,  0.02091592, ...,\n",
       "                         0.06699989, -0.04058601, -0.05693294],\n",
       "                       [ 0.03180134, -0.07817869, -0.0232802 , ...,\n",
       "                         0.04955521,  0.04651733, -0.03963707],\n",
       "                       [ 0.02683936,  0.01995781, -0.02373235, ...,\n",
       "                        -0.00647717,  0.01866268,  0.03389529],\n",
       "                       ...,\n",
       "                       [ 0.03252535, -0.02808473,  0.01797205, ...,\n",
       "                         0.00882896,  0.04806598,  0.01011384],\n",
       "                       [ 0.16386507, -0.0752492 , -0.0051812 , ...,\n",
       "                        -0.04416445, -0.10120002,  0.08909234],\n",
       "                       [-0.02085042, -0.02922694, -0.16262046, ...,\n",
       "                         0.01183743, -0.03865601, -0.07858766]],\n",
       "  \n",
       "                      [[ 0.06121506, -0.04401897,  0.02243254, ...,\n",
       "                         0.01176416,  0.0672584 ,  0.02163697],\n",
       "                       [-0.00355951, -0.009473  ,  0.00317546, ...,\n",
       "                        -0.02355136,  0.04021157,  0.00231776],\n",
       "                       [-0.04057062,  0.13747865, -0.05452013, ...,\n",
       "                         0.1466413 , -0.01958448,  0.02075738],\n",
       "                       ...,\n",
       "                       [ 0.1184539 ,  0.10589124, -0.05610298, ...,\n",
       "                         0.04791516,  0.02239982, -0.21898055],\n",
       "                       [-0.07183348, -0.04229408, -0.04583135, ...,\n",
       "                         0.02320969, -0.05380469, -0.05135102],\n",
       "                       [ 0.00719213, -0.07366481,  0.00629014, ...,\n",
       "                        -0.03888618,  0.09317791, -0.03956376]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.1136457 , -0.34277168, -0.4579971 , ...,\n",
       "                        0.3414076 ,  0.35248604, -0.48974714],\n",
       "                      [ 0.1136457 , -0.34277168, -0.4579971 , ...,\n",
       "                        0.3414076 ,  0.35248604, -0.48974714]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-0.04949952,  0.00757091,  0.00524308, ...,\n",
       "                        -0.00771414,  0.00395798, -0.01012485],\n",
       "                       [-0.00195746,  0.01485744, -0.06279368, ...,\n",
       "                         0.0219605 ,  0.02876116,  0.00552493],\n",
       "                       [ 0.05175879,  0.09083731,  0.02492102, ...,\n",
       "                         0.1016866 , -0.11308395,  0.0245533 ],\n",
       "                       ...,\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ]],\n",
       "  \n",
       "                      [[ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       ...,\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ],\n",
       "                       [ 0.        ,  0.        ,  0.        , ...,\n",
       "                         0.        ,  0.        ,  0.        ]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00091684, -0.00285047, -0.00670006, ...,\n",
       "                        0.00420903,  0.00318488, -0.00227637],\n",
       "                      [ 0.00378126, -0.00410527, -0.00292978, ...,\n",
       "                        0.00348063,  0.00446184, -0.00842731]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.0041977 , -0.00177902,  0.00511602, ...,\n",
       "                       -0.01245412,  0.01135618,  0.01649996],\n",
       "                      [ 0.00584545, -0.00410623, -0.00084892, ...,\n",
       "                       -0.0108143 ,  0.0007224 ,  0.00621082]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-1.04095635e-03, -6.01732871e-04, -6.55394746e-04,\n",
       "                        ...,  9.78628959e-05, -4.03820159e-05,\n",
       "                         1.09952281e-03],\n",
       "                       [-2.39087560e-04,  3.25173569e-05,  4.28857631e-04,\n",
       "                        ...,  1.46996207e-03,  1.38795149e-04,\n",
       "                        -5.56748884e-04],\n",
       "                       [-6.22212247e-05, -6.96673174e-04,  5.18992485e-04,\n",
       "                        ...,  8.31951853e-04, -9.34712065e-04,\n",
       "                        -7.63728400e-04],\n",
       "                       ...,\n",
       "                       [-3.03955574e-04, -6.43322594e-04,  1.09236105e-03,\n",
       "                        ..., -5.16397959e-05, -1.09955983e-03,\n",
       "                        -3.50323156e-04],\n",
       "                       [-4.80022194e-04, -3.55002441e-04, -1.05947815e-03,\n",
       "                        ..., -1.53666444e-03, -6.72877184e-04,\n",
       "                        -3.88127155e-05],\n",
       "                       [-3.55731900e-04,  2.88630137e-04, -3.41982028e-04,\n",
       "                        ...,  2.70536169e-04,  1.23830023e-03,\n",
       "                         5.60816727e-04]],\n",
       "  \n",
       "                      [[ 1.19822376e-04,  1.14174688e-03,  3.80547281e-04,\n",
       "                        ..., -5.20666537e-04, -7.47081125e-04,\n",
       "                        -8.51778255e-04],\n",
       "                       [-1.00062840e-04, -9.52587696e-04,  8.74419347e-04,\n",
       "                        ..., -2.18143032e-04, -4.64279117e-04,\n",
       "                         9.01531894e-04],\n",
       "                       [ 7.32357905e-04, -5.05116303e-04, -9.41824183e-05,\n",
       "                        ..., -2.54860643e-04, -2.22698378e-04,\n",
       "                         3.98440316e-04],\n",
       "                       ...,\n",
       "                       [ 2.07866979e-04, -2.10682760e-04, -1.26826431e-04,\n",
       "                        ..., -1.04776269e-03, -6.59629994e-04,\n",
       "                         6.47400157e-05],\n",
       "                       [-8.86955182e-04, -8.28444681e-05,  5.96333994e-04,\n",
       "                        ...,  1.01574895e-03,  7.72920685e-05,\n",
       "                        -3.97573662e-04],\n",
       "                       [ 1.17943715e-03,  1.51600956e-03, -5.52494894e-04,\n",
       "                        ...,  6.89632958e-04,  4.76041285e-04,\n",
       "                        -9.02103842e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[-4.94015112e-04,  9.66930820e-04, -1.00580265e-03,\n",
       "                        ...,  6.88291853e-04,  7.57600530e-04,\n",
       "                        -9.08132060e-05],\n",
       "                       [-4.27178253e-04,  1.16667936e-04,  6.59875106e-04,\n",
       "                        ..., -4.90379694e-04, -3.55117314e-04,\n",
       "                         5.00889611e-04],\n",
       "                       [ 2.73843762e-04, -4.62461147e-04, -7.56726076e-04,\n",
       "                        ...,  6.52540475e-05,  2.36684908e-04,\n",
       "                        -1.23285921e-03],\n",
       "                       ...,\n",
       "                       [-4.32126399e-05, -1.53540436e-03, -2.81874003e-04,\n",
       "                        ...,  1.29253091e-03, -1.02303980e-03,\n",
       "                         1.06445048e-03],\n",
       "                       [ 7.49383180e-04,  9.19685117e-04,  2.38524852e-04,\n",
       "                        ...,  6.19182363e-04,  6.30999333e-04,\n",
       "                        -1.04029372e-03],\n",
       "                       [-7.09574786e-04,  7.32105982e-04,  3.13923927e-04,\n",
       "                        ...,  4.25950770e-04, -2.99879524e-04,\n",
       "                         9.18818405e-04]],\n",
       "  \n",
       "                      [[ 5.06456243e-04, -4.48635605e-04, -4.56898852e-06,\n",
       "                        ...,  1.52510518e-04,  5.37667540e-04,\n",
       "                        -8.18462635e-04],\n",
       "                       [-3.54060554e-04, -6.93622278e-04, -1.00202707e-03,\n",
       "                        ...,  2.01125018e-04,  7.31375127e-04,\n",
       "                        -2.80210545e-04],\n",
       "                       [-2.79183529e-04,  1.48101395e-03, -3.19023820e-04,\n",
       "                        ..., -4.68006154e-04,  1.61574013e-03,\n",
       "                        -9.16641322e-04],\n",
       "                       ...,\n",
       "                       [-2.20998088e-04,  1.49179774e-03,  1.19422725e-03,\n",
       "                        ..., -2.03647010e-04, -1.53213085e-04,\n",
       "                         4.44790057e-04],\n",
       "                       [ 3.92615999e-04,  7.57847214e-04, -5.57744585e-04,\n",
       "                        ...,  3.13320314e-04, -1.06215337e-03,\n",
       "                         4.28698375e-04],\n",
       "                       [ 2.77726911e-04,  4.46775375e-04,  2.81637534e-04,\n",
       "                        ...,  1.10782137e-04, -5.45241695e-04,\n",
       "                         6.14684308e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 1.6301729e-03,  8.7358209e-04,  1.5709959e-03,\n",
       "                        ...,  1.5817644e-03,  3.8620766e-04,\n",
       "                        -1.4195275e-03],\n",
       "                       [ 1.6320482e-03, -9.4260817e-04, -2.1358400e-04,\n",
       "                        ...,  5.8648706e-04, -8.0031791e-04,\n",
       "                         4.6411798e-05],\n",
       "                       [-6.5502815e-04, -1.6939067e-03, -2.3031661e-03,\n",
       "                        ..., -6.4735555e-05,  4.5891773e-04,\n",
       "                        -1.0356739e-03],\n",
       "                       ...,\n",
       "                       [-5.7214202e-04, -1.7631493e-03,  1.5730240e-03,\n",
       "                        ...,  8.9582748e-04, -2.9956633e-03,\n",
       "                         1.0160543e-03],\n",
       "                       [-3.6000169e-04, -3.5698216e-05,  1.7578659e-03,\n",
       "                        ..., -8.3724575e-05, -3.7912431e-04,\n",
       "                        -2.5611646e-03],\n",
       "                       [-3.1123245e-03, -2.7425613e-04,  2.5815179e-03,\n",
       "                        ..., -7.7936967e-04, -2.2597492e-03,\n",
       "                        -2.3878790e-03]],\n",
       "  \n",
       "                      [[-1.8094113e-04,  2.8753133e-05,  1.7273813e-04,\n",
       "                        ..., -8.8176754e-04, -2.0455832e-03,\n",
       "                        -8.2574392e-05],\n",
       "                       [ 1.9522578e-03, -3.2148676e-03,  8.2422240e-04,\n",
       "                        ...,  3.7507311e-04, -1.5462545e-03,\n",
       "                        -3.8316119e-03],\n",
       "                       [-2.5395562e-03, -1.9864496e-03, -8.0460665e-04,\n",
       "                        ..., -3.2800590e-04,  8.2323147e-04,\n",
       "                         2.0691601e-03],\n",
       "                       ...,\n",
       "                       [ 2.5490818e-03, -1.3188551e-03,  9.8212867e-04,\n",
       "                        ...,  2.4414372e-03, -7.8942109e-04,\n",
       "                        -2.4475164e-03],\n",
       "                       [ 3.7942900e-05,  1.3243119e-03, -1.8215103e-03,\n",
       "                        ...,  1.2602629e-03,  1.4096592e-03,\n",
       "                         1.0585403e-03],\n",
       "                       [-3.4936829e-03, -2.2069288e-03, -2.1781963e-03,\n",
       "                        ..., -2.7683878e-04, -1.4150868e-03,\n",
       "                         8.7594491e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 1.27877260e-03, -9.95811773e-04,  9.87355364e-04,\n",
       "                        ...,  4.26437473e-03, -2.14859814e-04,\n",
       "                         2.59457319e-03],\n",
       "                       [ 4.79691284e-04,  1.90772582e-03,  1.58893774e-04,\n",
       "                        ..., -1.47929194e-03, -1.08036038e-03,\n",
       "                        -6.19484286e-04],\n",
       "                       [ 2.42794980e-03, -5.35436498e-04, -4.19605029e-04,\n",
       "                        ...,  2.66827701e-04,  2.33683991e-03,\n",
       "                        -1.81445910e-03],\n",
       "                       ...,\n",
       "                       [-1.36809843e-03, -1.58630032e-03, -9.16279620e-04,\n",
       "                        ..., -5.02448413e-04, -6.85597071e-04,\n",
       "                         1.58098363e-03],\n",
       "                       [-1.04305928e-03,  1.29530759e-04, -1.04530358e-04,\n",
       "                        ...,  1.31930993e-03, -4.68211423e-04,\n",
       "                        -4.21180535e-04],\n",
       "                       [ 2.21715588e-03,  1.05648162e-03, -1.55103218e-03,\n",
       "                        ...,  8.82126740e-04,  1.11010806e-04,\n",
       "                        -4.53022192e-04]],\n",
       "  \n",
       "                      [[-3.40585154e-03,  1.29092281e-04,  2.19481555e-03,\n",
       "                        ...,  2.43863236e-04, -1.96638610e-03,\n",
       "                         2.33065034e-03],\n",
       "                       [ 4.61843424e-03, -2.34395266e-03, -9.64865612e-04,\n",
       "                        ...,  2.31379154e-03, -1.01128663e-03,\n",
       "                         1.62605988e-03],\n",
       "                       [ 6.29925460e-04, -8.57852108e-04,  1.43501686e-03,\n",
       "                        ...,  1.23496214e-03, -1.07647164e-03,\n",
       "                         3.17465584e-03],\n",
       "                       ...,\n",
       "                       [-1.00555585e-03, -1.12737797e-03, -6.38986414e-04,\n",
       "                        ..., -1.73557608e-03,  1.60502514e-03,\n",
       "                         2.66421703e-03],\n",
       "                       [ 1.82803033e-03, -2.04025698e-03, -1.19823765e-03,\n",
       "                        ..., -8.05554155e-05,  9.48734523e-04,\n",
       "                         3.47354938e-03],\n",
       "                       [-2.24970537e-03,  1.70732196e-03, -1.06217660e-04,\n",
       "                        ..., -9.69871006e-04,  3.25194065e-04,\n",
       "                        -3.85763007e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 6.7333411e-04, -6.9668668e-04, -1.8506597e-03, ...,\n",
       "                       -2.7131711e-03, -1.1855154e-03,  1.7912035e-03],\n",
       "                      [-3.8013861e-03, -2.4324979e-03,  7.1455922e-04, ...,\n",
       "                        4.8587326e-06,  6.4321933e-04, -2.6065011e-03]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-8.9554262e-05, -4.4196509e-03, -2.2447598e-03,\n",
       "                        ..., -1.0384388e-03,  1.0214085e-03,\n",
       "                         1.7152894e-03],\n",
       "                       [ 2.7277609e-04,  3.6451572e-03,  8.3971908e-04,\n",
       "                        ...,  1.2314469e-03, -3.4251992e-04,\n",
       "                         1.7588574e-03],\n",
       "                       [ 1.7146642e-03, -7.5030548e-04, -4.6545239e-03,\n",
       "                        ...,  8.8104549e-05,  2.8298323e-03,\n",
       "                         2.8687681e-03],\n",
       "                       ...,\n",
       "                       [ 3.2565309e-04,  2.8463497e-03, -1.2328731e-03,\n",
       "                        ...,  3.0579609e-03, -5.3206695e-05,\n",
       "                         1.2066871e-03],\n",
       "                       [-1.5515160e-03, -3.2421066e-03,  1.2160218e-05,\n",
       "                        ...,  1.9969973e-03,  2.2001022e-03,\n",
       "                         6.8982975e-03],\n",
       "                       [-7.8219251e-04,  3.2806203e-03, -5.6857755e-04,\n",
       "                        ..., -1.4297176e-03,  2.2082401e-03,\n",
       "                         4.7043120e-03]],\n",
       "  \n",
       "                      [[ 2.7303569e-04, -2.2613388e-04,  1.6614760e-03,\n",
       "                        ...,  2.3567816e-03, -5.9713790e-04,\n",
       "                        -1.3067881e-03],\n",
       "                       [ 5.6008721e-04, -1.5801241e-04, -7.2440220e-04,\n",
       "                        ..., -4.4880432e-04,  1.9076819e-03,\n",
       "                        -4.1040061e-03],\n",
       "                       [ 1.4822228e-03, -1.6511695e-03,  3.5733653e-03,\n",
       "                        ..., -2.7563190e-03, -9.6645155e-05,\n",
       "                        -1.1297636e-03],\n",
       "                       ...,\n",
       "                       [ 7.4266545e-03, -2.2637958e-03,  6.0101197e-04,\n",
       "                        ..., -5.2255318e-03,  2.3615762e-04,\n",
       "                         1.6669709e-03],\n",
       "                       [-1.0022400e-03, -7.4154865e-03,  1.5717819e-03,\n",
       "                        ..., -7.2839153e-03,  7.2361919e-04,\n",
       "                        -1.3113981e-04],\n",
       "                       [-3.1140691e-03,  4.1969446e-04,  1.9172651e-03,\n",
       "                        ..., -4.7155465e-03, -9.9649094e-04,\n",
       "                        -1.1201473e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.0033207 , -0.00161125, -0.00191672, ...,\n",
       "                        0.00192672,  0.00375562, -0.00506669],\n",
       "                      [ 0.0033207 , -0.00161125, -0.00191672, ...,\n",
       "                        0.00192672,  0.00375562, -0.00506669]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 3.3811904e-03, -6.7342509e-04,  1.8346071e-03,\n",
       "                        ...,  1.0305024e-03,  1.0940399e-03,\n",
       "                        -1.4900676e-03],\n",
       "                       [ 5.1965495e-03, -4.8009586e-03,  8.9187990e-04,\n",
       "                        ..., -2.2079755e-04,  1.9467592e-03,\n",
       "                        -2.1168001e-03],\n",
       "                       [ 2.7053226e-03, -2.1555431e-03,  2.4623512e-03,\n",
       "                        ..., -1.7392462e-03,  6.5923529e-04,\n",
       "                        -2.1792534e-03],\n",
       "                       ...,\n",
       "                       [-7.4519694e-04,  3.1896387e-04,  3.4939263e-03,\n",
       "                        ...,  1.6448753e-03,  6.2709651e-04,\n",
       "                         9.6659386e-04],\n",
       "                       [ 4.9253489e-04,  1.1372665e-03, -2.2352557e-03,\n",
       "                        ..., -1.4956705e-03,  2.6101943e-03,\n",
       "                         1.7070689e-03],\n",
       "                       [-7.6955665e-05,  1.8120393e-03, -1.2530928e-03,\n",
       "                        ...,  4.5210784e-04, -1.9278830e-03,\n",
       "                        -3.2475083e-03]],\n",
       "  \n",
       "                      [[-1.6580835e-04, -5.0623529e-03, -2.7219499e-03,\n",
       "                        ...,  2.3689099e-04,  3.4041627e-04,\n",
       "                         1.5580663e-03],\n",
       "                       [-4.3091159e-03,  3.1438372e-03, -5.6821975e-04,\n",
       "                        ..., -1.5616697e-03, -3.1929967e-04,\n",
       "                        -5.9478747e-04],\n",
       "                       [-1.5357349e-03, -1.9045428e-03, -4.4774599e-03,\n",
       "                        ...,  2.7934222e-03,  1.4465186e-03,\n",
       "                        -4.0059281e-03],\n",
       "                       ...,\n",
       "                       [ 2.5686817e-03,  7.8705658e-04, -2.4576231e-03,\n",
       "                        ..., -2.1394677e-03, -4.4190197e-04,\n",
       "                         8.8539306e-04],\n",
       "                       [ 3.5240647e-04, -7.5377116e-04, -1.3144041e-04,\n",
       "                        ...,  4.6071943e-04, -1.1145639e-03,\n",
       "                         2.7546750e-03],\n",
       "                       [ 2.9063094e-03,  9.4246527e-04, -3.1148423e-03,\n",
       "                        ..., -4.2959821e-04, -8.7386783e-04,\n",
       "                         5.5756224e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.00179346, -0.00068035, -0.00340598, ...,\n",
       "                        0.00092189,  0.0007601 , -0.00290959],\n",
       "                      [ 0.00250817, -0.00365363, -0.00109188, ...,\n",
       "                       -0.00074607,  0.00383001, -0.00257633]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.00117909, -0.00014617, -0.00362114, ...,\n",
       "                       -0.00315083, -0.00026001,  0.00046211],\n",
       "                      [-0.00109883, -0.00370035, -0.00447193, ...,\n",
       "                       -0.00573193,  0.00025492,  0.00240487]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-1.8821932e-04, -8.3769852e-04,  4.6706476e-04,\n",
       "                        ...,  7.9443364e-04,  3.0453435e-05,\n",
       "                         3.2804455e-04],\n",
       "                       [ 2.0236500e-04, -3.4040975e-04, -7.1721265e-06,\n",
       "                        ...,  2.0276735e-04,  3.4307434e-06,\n",
       "                         5.8543766e-05],\n",
       "                       [-5.8662443e-04,  1.0859401e-04,  5.5330974e-04,\n",
       "                        ...,  3.8202055e-04, -2.7649340e-04,\n",
       "                        -3.7283049e-04],\n",
       "                       ...,\n",
       "                       [-2.5388543e-04, -2.0783446e-04, -4.5109147e-04,\n",
       "                        ..., -1.5730820e-04,  1.3671075e-04,\n",
       "                        -2.3548821e-05],\n",
       "                       [ 4.3571880e-04,  5.1419181e-04, -6.3655648e-04,\n",
       "                        ...,  9.9573714e-05,  1.0903517e-03,\n",
       "                         3.2657079e-04],\n",
       "                       [ 2.4817703e-06,  3.4376746e-04,  1.9487368e-05,\n",
       "                        ..., -2.2375325e-04,  6.3070178e-04,\n",
       "                        -1.5124305e-04]],\n",
       "  \n",
       "                      [[-1.4899613e-04,  4.7552548e-06, -2.0253910e-04,\n",
       "                        ...,  3.1715343e-04,  8.4232641e-05,\n",
       "                         2.7577677e-05],\n",
       "                       [-6.5379383e-05, -1.0388961e-04,  7.2357456e-05,\n",
       "                        ..., -6.1246700e-04,  2.3271100e-04,\n",
       "                        -3.9851002e-05],\n",
       "                       [-1.7076901e-04,  7.1913586e-05, -7.6079632e-06,\n",
       "                        ...,  2.6313981e-04,  2.5099452e-04,\n",
       "                         1.7620692e-04],\n",
       "                       ...,\n",
       "                       [ 4.1089956e-05, -4.8964581e-04,  3.7107675e-04,\n",
       "                        ..., -2.8852650e-04, -5.5070850e-04,\n",
       "                        -5.3461845e-04],\n",
       "                       [ 1.9120819e-04, -6.3462101e-04,  3.1061264e-04,\n",
       "                        ...,  7.5416686e-04, -2.5155224e-04,\n",
       "                         1.2824882e-04],\n",
       "                       [-2.2522858e-05,  1.2719622e-04, -9.6036041e-05,\n",
       "                        ..., -3.0587128e-04,  4.7242444e-04,\n",
       "                         4.7694225e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 8.9162757e-04,  2.7814027e-04, -1.5774790e-04,\n",
       "                        ..., -4.1455700e-04, -3.1291292e-04,\n",
       "                        -1.2264586e-04],\n",
       "                       [ 1.0344435e-04, -2.5019805e-05,  1.9283172e-04,\n",
       "                        ..., -1.4744277e-05,  1.3115400e-04,\n",
       "                         2.0673734e-04],\n",
       "                       [-4.6038348e-04, -2.6771086e-04, -3.9367631e-04,\n",
       "                        ..., -6.1589591e-05, -2.9997341e-04,\n",
       "                         9.8997414e-05],\n",
       "                       ...,\n",
       "                       [-1.9829902e-04, -1.0255853e-03,  6.1467785e-04,\n",
       "                        ..., -1.8751698e-05, -5.7283120e-04,\n",
       "                         1.2847545e-04],\n",
       "                       [ 6.7644980e-04,  4.8438762e-04, -6.3904496e-05,\n",
       "                        ..., -2.6573354e-04,  2.9454599e-04,\n",
       "                        -2.7066862e-04],\n",
       "                       [-1.0638300e-03,  3.5601383e-06,  2.6894748e-04,\n",
       "                        ...,  2.1033063e-04,  3.8152345e-04,\n",
       "                        -1.2639738e-04]],\n",
       "  \n",
       "                      [[-1.9286496e-04, -1.8921902e-04,  2.1289389e-04,\n",
       "                        ...,  5.8504468e-04, -2.0433447e-04,\n",
       "                        -1.3068342e-04],\n",
       "                       [-4.6449836e-04,  6.0542428e-04, -4.5951738e-04,\n",
       "                        ..., -1.8515242e-05, -3.0536938e-04,\n",
       "                         2.0537690e-04],\n",
       "                       [-2.7539369e-04, -2.4095965e-04,  5.1869874e-06,\n",
       "                        ..., -4.2671534e-05,  3.7895484e-04,\n",
       "                        -6.4160023e-04],\n",
       "                       ...,\n",
       "                       [ 1.2987143e-04, -1.2865114e-04,  2.7586333e-05,\n",
       "                        ...,  2.4786839e-04,  2.6573912e-06,\n",
       "                         2.7611479e-04],\n",
       "                       [-3.7914804e-05, -1.2101996e-04,  8.5816955e-06,\n",
       "                        ...,  2.2756671e-04, -4.2930272e-04,\n",
       "                        -1.6969015e-04],\n",
       "                       [-2.1189798e-04, -2.7185254e-04,  2.9561960e-04,\n",
       "                        ..., -3.6533139e-04,  1.8648290e-04,\n",
       "                         5.3489668e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[-9.59436074e-05, -7.46329257e-04, -1.11485118e-04,\n",
       "                        ..., -9.02093132e-04,  6.58146673e-05,\n",
       "                        -3.32314434e-04],\n",
       "                       [ 4.45300859e-04,  1.62138313e-03,  4.83595446e-04,\n",
       "                        ..., -5.21217298e-04,  1.28392887e-03,\n",
       "                         1.32228713e-03],\n",
       "                       [ 6.88132714e-04, -4.71508451e-04,  2.19173962e-04,\n",
       "                        ...,  1.18116860e-03, -4.60818148e-04,\n",
       "                         4.10766457e-04],\n",
       "                       ...,\n",
       "                       [-1.32099714e-03, -3.48259782e-04,  2.61383189e-04,\n",
       "                        ..., -2.86406663e-04, -1.33604789e-03,\n",
       "                         5.33480721e-04],\n",
       "                       [-1.00679649e-03,  8.46697803e-05,  2.65111710e-04,\n",
       "                        ...,  4.14599606e-04,  2.25518001e-04,\n",
       "                         4.05348866e-04],\n",
       "                       [ 2.17344175e-04,  3.05894413e-04,  1.17803819e-03,\n",
       "                        ...,  6.15970988e-04,  7.28356943e-04,\n",
       "                         2.52019934e-04]],\n",
       "  \n",
       "                      [[-1.75119459e-03, -2.03551463e-04, -8.72610835e-04,\n",
       "                        ..., -3.95690731e-04, -2.53956276e-03,\n",
       "                         3.32178693e-04],\n",
       "                       [ 1.75866298e-03,  1.00422796e-04,  9.88958054e-04,\n",
       "                        ..., -2.76220264e-04,  1.00887346e-03,\n",
       "                         1.26561581e-03],\n",
       "                       [ 1.12529891e-03, -6.83212129e-04,  1.28688407e-03,\n",
       "                        ..., -1.39313022e-04,  3.70673893e-04,\n",
       "                         9.21444444e-04],\n",
       "                       ...,\n",
       "                       [-7.24101032e-04, -4.58394235e-04, -1.08235923e-03,\n",
       "                        ..., -3.68494602e-06,  1.22864137e-03,\n",
       "                         1.15782081e-03],\n",
       "                       [-1.26578927e-03, -9.67789092e-05,  3.94704170e-04,\n",
       "                        ..., -1.21028349e-03, -1.56005134e-03,\n",
       "                        -8.75621801e-04],\n",
       "                       [ 2.98120984e-04,  1.04075484e-03,  1.36864127e-03,\n",
       "                        ..., -5.16810280e-04,  3.31430754e-04,\n",
       "                        -4.98502457e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 6.2284969e-05,  9.3224703e-04, -5.0398603e-04,\n",
       "                        ..., -9.9303779e-06,  1.9290883e-05,\n",
       "                        -2.0380267e-04],\n",
       "                       [ 2.4638436e-04, -1.2159090e-03, -1.5789818e-04,\n",
       "                        ..., -1.2757693e-04, -5.6157610e-04,\n",
       "                         2.5378510e-03],\n",
       "                       [ 2.8580052e-04, -1.8785155e-04,  1.6285045e-04,\n",
       "                        ..., -2.1408832e-05,  3.8556702e-04,\n",
       "                        -9.3247020e-04],\n",
       "                       ...,\n",
       "                       [-1.7730928e-03,  4.8523583e-04,  1.4058943e-04,\n",
       "                        ..., -1.8003391e-03, -1.0205877e-03,\n",
       "                         3.1815373e-04],\n",
       "                       [ 1.0475315e-03, -1.4173125e-03,  4.6044047e-04,\n",
       "                        ..., -7.9267644e-05, -1.6112062e-04,\n",
       "                         1.9485459e-03],\n",
       "                       [ 1.5266290e-03,  5.5222871e-04,  1.7022375e-04,\n",
       "                        ...,  2.7314443e-03, -2.5805464e-04,\n",
       "                        -4.1676467e-04]],\n",
       "  \n",
       "                      [[ 2.6260066e-04,  5.4669301e-05, -1.1320027e-03,\n",
       "                        ..., -7.8856025e-04,  8.1137917e-04,\n",
       "                         2.1666480e-04],\n",
       "                       [-1.3301796e-03,  1.3471547e-03,  8.1722758e-04,\n",
       "                        ..., -1.4304746e-03, -3.1670439e-04,\n",
       "                        -2.6443705e-03],\n",
       "                       [-9.6932007e-04,  5.1329657e-04,  2.7393462e-04,\n",
       "                        ...,  1.0315347e-03,  5.1888684e-04,\n",
       "                        -5.3592539e-05],\n",
       "                       ...,\n",
       "                       [-1.0477536e-03, -2.5163058e-04,  8.4521127e-04,\n",
       "                        ..., -1.9344810e-05,  3.8289186e-04,\n",
       "                         1.1709313e-03],\n",
       "                       [ 7.2101055e-04,  2.8332535e-04,  6.5993844e-04,\n",
       "                        ..., -1.9564993e-04, -8.3457859e-04,\n",
       "                        -4.6033924e-04],\n",
       "                       [ 1.0858487e-03,  7.2216376e-04, -9.8291232e-05,\n",
       "                        ..., -3.8142767e-04, -4.0985373e-04,\n",
       "                        -1.6510698e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00155545, -0.00139999, -0.00013433, ...,\n",
       "                       -0.0017168 , -0.00086697, -0.0017649 ],\n",
       "                      [ 0.00084107, -0.00205688, -0.00108209, ...,\n",
       "                       -0.00029415, -0.00046804, -0.00059863]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-6.7466346e-04,  7.7330944e-04, -1.6044896e-03,\n",
       "                        ..., -1.7640238e-03,  1.9726015e-03,\n",
       "                         3.0231336e-04],\n",
       "                       [ 3.9048228e-04, -1.6228455e-03,  1.1170232e-03,\n",
       "                        ...,  9.0963126e-04, -2.8667797e-03,\n",
       "                        -1.2791273e-03],\n",
       "                       [-2.5374182e-03,  1.2698150e-04, -1.6041988e-03,\n",
       "                        ..., -1.5843500e-03,  1.6742058e-03,\n",
       "                        -7.3800579e-04],\n",
       "                       ...,\n",
       "                       [ 2.4478650e-03,  2.7235571e-04,  8.3612307e-04,\n",
       "                        ...,  8.6844806e-04,  1.6631868e-03,\n",
       "                        -7.1025884e-04],\n",
       "                       [-8.6120074e-04,  1.8619020e-03,  8.9896435e-04,\n",
       "                        ..., -7.0625567e-04,  2.3749247e-03,\n",
       "                        -1.9021798e-03],\n",
       "                       [-5.5882812e-04, -1.7490785e-03,  4.6873724e-04,\n",
       "                        ...,  5.2418676e-04,  1.0431478e-03,\n",
       "                        -2.5831466e-03]],\n",
       "  \n",
       "                      [[ 9.9811237e-04,  5.6743604e-04, -1.5204596e-04,\n",
       "                        ...,  8.7453995e-04,  1.9827790e-03,\n",
       "                        -8.6780591e-04],\n",
       "                       [-8.3104562e-04,  6.1766099e-04, -1.1420535e-03,\n",
       "                        ..., -1.2271189e-04, -9.4090874e-04,\n",
       "                         1.0337791e-03],\n",
       "                       [-7.8197329e-05, -1.6344164e-03,  4.2042838e-04,\n",
       "                        ...,  2.7173819e-04,  5.8459432e-04,\n",
       "                        -5.8545865e-04],\n",
       "                       ...,\n",
       "                       [ 4.5210454e-05,  2.3012208e-03, -4.4998219e-06,\n",
       "                        ...,  9.9328137e-04,  1.0724944e-03,\n",
       "                        -4.1312465e-04],\n",
       "                       [ 2.2430567e-03, -2.4016721e-03,  9.1947033e-04,\n",
       "                        ...,  5.4401498e-05,  2.5550430e-03,\n",
       "                         1.4680016e-03],\n",
       "                       [ 7.9831667e-04, -1.3061609e-03,  1.5602133e-03,\n",
       "                        ..., -2.4281020e-04, -4.1234880e-04,\n",
       "                         1.8709578e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.00168984, -0.00011539, -0.00050136, ...,\n",
       "                        0.00225048,  0.00184357, -0.00321637],\n",
       "                      [ 0.00168984, -0.00011539, -0.00050136, ...,\n",
       "                        0.00225048,  0.00184357, -0.00321637]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-3.5513830e-04, -2.9425617e-04,  2.8305597e-04,\n",
       "                        ..., -3.5902369e-04,  1.3102958e-04,\n",
       "                         7.6067704e-04],\n",
       "                       [-8.5538684e-04,  9.0298687e-05, -5.7526026e-04,\n",
       "                        ...,  2.0460060e-04, -5.0642772e-04,\n",
       "                        -1.1325715e-03],\n",
       "                       [-2.9348661e-03, -1.4033130e-03,  7.1654760e-04,\n",
       "                        ...,  1.7772949e-03, -6.4147171e-04,\n",
       "                        -7.2306735e-05],\n",
       "                       ...,\n",
       "                       [-1.3100733e-04,  1.8286973e-03,  2.0015277e-03,\n",
       "                        ..., -7.7796570e-04,  1.3608638e-03,\n",
       "                        -1.9826021e-03],\n",
       "                       [-1.0943251e-03,  2.3108325e-03, -6.8284449e-04,\n",
       "                        ..., -6.6342519e-04, -4.2133033e-04,\n",
       "                        -1.8498757e-05],\n",
       "                       [ 5.6912290e-04, -3.3661462e-03,  6.2317075e-04,\n",
       "                        ...,  2.2158029e-03, -5.6196743e-04,\n",
       "                        -2.1335899e-03]],\n",
       "  \n",
       "                      [[ 4.9493532e-04, -7.0448208e-04,  1.0151590e-03,\n",
       "                        ..., -4.0594296e-04, -1.0079717e-03,\n",
       "                        -6.9161080e-04],\n",
       "                       [-2.2481596e-03,  3.7568163e-05, -9.4899733e-04,\n",
       "                        ..., -5.4562217e-05, -1.5422085e-04,\n",
       "                        -4.6658190e-04],\n",
       "                       [ 1.4496959e-03,  4.1738385e-04,  3.8633600e-04,\n",
       "                        ...,  1.5328800e-03, -6.9454609e-04,\n",
       "                        -1.9339882e-03],\n",
       "                       ...,\n",
       "                       [ 1.1350452e-03, -8.0833293e-04, -1.4165826e-03,\n",
       "                        ...,  3.0020012e-03,  1.9383029e-03,\n",
       "                        -3.2348977e-04],\n",
       "                       [ 1.9868252e-04, -1.1897843e-03, -1.3380214e-03,\n",
       "                        ...,  7.1525562e-04,  1.4397422e-04,\n",
       "                        -7.7380886e-04],\n",
       "                       [-1.4408963e-07,  1.9834952e-03, -4.1622249e-04,\n",
       "                        ...,  8.3553512e-04,  3.2207451e-03,\n",
       "                        -5.9219631e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.01248832, -0.00391468, -0.01305332, ...,\n",
       "                        0.01883796,  0.01450661, -0.02406795],\n",
       "                      [-0.00031419, -0.00272206,  0.00058785, ...,\n",
       "                       -0.00229262,  0.00070049, -0.0019914 ]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.01090593, -0.02379955, -0.01997396, ...,\n",
       "                       -0.03642803, -0.0159413 , -0.0143337 ],\n",
       "                      [ 0.00171677,  0.00014177,  0.00148769, ...,\n",
       "                        0.0018454 ,  0.00116951,  0.00022535]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.02485867, -0.03316229, -0.07635134, ...,\n",
       "                        0.00220315,  0.00242402,  0.00215389],\n",
       "                      [ 0.00323853,  0.00227009,  0.00219144, ...,\n",
       "                        0.00166518,  0.00216391,  0.00380728]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 1.52112835e-03,  2.35234872e-02,  4.03714627e-02,\n",
       "                        ..., -2.90658121e-04, -1.44917751e-04,\n",
       "                         2.69705895e-04],\n",
       "                       [-1.68470088e-02, -2.58613043e-02, -1.09253768e-02,\n",
       "                        ...,  6.51941227e-04,  4.07236425e-04,\n",
       "                         1.39652670e-03],\n",
       "                       [ 4.46453225e-03,  9.75017995e-03,  5.80900311e-02,\n",
       "                        ...,  7.63357617e-04,  2.00147368e-03,\n",
       "                         1.09817646e-03],\n",
       "                       ...,\n",
       "                       [-4.03025523e-02,  5.07697724e-02,  6.74371272e-02,\n",
       "                        ..., -6.39165868e-04, -6.53231400e-04,\n",
       "                        -4.10168053e-04],\n",
       "                       [-5.13184408e-04,  7.22634839e-03,  1.36804553e-02,\n",
       "                        ..., -3.02907312e-04, -4.60379757e-04,\n",
       "                        -7.33623572e-04],\n",
       "                       [-5.66945076e-02, -1.68297719e-02, -7.65456632e-03,\n",
       "                        ...,  1.60465215e-03,  9.45935317e-04,\n",
       "                         1.34948944e-03]],\n",
       "  \n",
       "                      [[-1.06242532e-03, -3.63223342e-04, -6.28566020e-04,\n",
       "                        ..., -1.21373805e-05, -3.13089346e-04,\n",
       "                        -1.26651872e-03],\n",
       "                       [ 1.16182980e-03,  9.63024562e-04,  8.35200015e-04,\n",
       "                        ...,  6.58414734e-04,  5.30290243e-04,\n",
       "                         1.00213918e-03],\n",
       "                       [ 1.63145852e-03,  8.92821234e-04,  1.09454535e-03,\n",
       "                        ...,  7.80765142e-04,  1.05322571e-03,\n",
       "                         2.04617064e-03],\n",
       "                       ...,\n",
       "                       [ 1.08566674e-04, -3.76496115e-04, -9.64298670e-04,\n",
       "                        ..., -3.07274720e-04, -1.51440836e-04,\n",
       "                        -1.67202041e-03],\n",
       "                       [-1.30543078e-04, -5.54061146e-04, -7.05776620e-04,\n",
       "                        ..., -4.92965570e-04, -4.29392850e-04,\n",
       "                        -1.05793471e-03],\n",
       "                       [ 1.83057785e-03,  1.17328879e-03,  1.26862805e-03,\n",
       "                        ...,  7.68591883e-04,  1.03984890e-03,\n",
       "                         2.36424757e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[1.27718807e-03, 6.58215664e-04, 8.70717340e-05,\n",
       "                        ..., 3.84430023e-04, 1.21538389e-04,\n",
       "                        4.82026167e-04],\n",
       "                       [1.76233181e-04, 3.82674509e-04, 1.55319140e-04,\n",
       "                        ..., 3.87119479e-04, 2.32746359e-04,\n",
       "                        1.99368165e-04],\n",
       "                       [3.40104452e-04, 1.56722919e-04, 1.40513977e-04,\n",
       "                        ..., 3.55579323e-05, 4.05528517e-05,\n",
       "                        2.15828069e-04],\n",
       "                       ...,\n",
       "                       [3.57129815e-04, 1.18403055e-04, 1.31887704e-04,\n",
       "                        ..., 9.01678723e-05, 1.81773910e-04,\n",
       "                        3.18500788e-05],\n",
       "                       [1.59988971e-03, 3.22880689e-04, 1.96130553e-04,\n",
       "                        ..., 2.85805931e-04, 7.38247472e-04,\n",
       "                        9.65015381e-04],\n",
       "                       [7.31139808e-05, 4.74659973e-05, 2.58789817e-03,\n",
       "                        ..., 3.21762891e-05, 2.27656739e-04,\n",
       "                        4.04116872e-04]],\n",
       "  \n",
       "                      [[2.84958602e-04, 4.39894618e-04, 6.54673553e-04,\n",
       "                        ..., 4.00148456e-05, 8.08791781e-04,\n",
       "                        3.77038959e-04],\n",
       "                       [5.00644346e-05, 7.44758800e-05, 1.98127425e-04,\n",
       "                        ..., 5.72145291e-05, 1.04788414e-04,\n",
       "                        1.65543664e-04],\n",
       "                       [1.16992138e-04, 1.66428695e-03, 3.79291974e-04,\n",
       "                        ..., 1.64265500e-03, 1.09525397e-04,\n",
       "                        9.96634990e-05],\n",
       "                       ...,\n",
       "                       [1.07511354e-03, 1.03761768e-03, 3.57437326e-04,\n",
       "                        ..., 3.28555790e-04, 1.82654258e-04,\n",
       "                        4.66168113e-03],\n",
       "                       [2.57896987e-04, 3.22436012e-04, 1.14486051e-04,\n",
       "                        ..., 2.30149541e-04, 1.48695573e-04,\n",
       "                        3.78237281e-04],\n",
       "                       [1.10251931e-04, 5.55571693e-04, 7.88221951e-05,\n",
       "                        ..., 1.43776124e-04, 8.62963148e-04,\n",
       "                        1.99526272e-04]]], dtype=float32),\n",
       "  ShardedDeviceArray([[0.0094556 , 0.01229713, 0.01829681, ..., 0.0379006 ,\n",
       "                       0.0160627 , 0.14616694],\n",
       "                      [0.0094556 , 0.01229713, 0.01829681, ..., 0.0379006 ,\n",
       "                       0.0160627 , 0.14616694]], dtype=float32),\n",
       "  ShardedDeviceArray([[[1.7925283e-04, 5.3495837e-06, 2.5566576e-06, ...,\n",
       "                        3.6123452e-06, 5.1502293e-06, 1.4932241e-05],\n",
       "                       [2.0151863e-07, 1.1576761e-05, 2.3209512e-04, ...,\n",
       "                        2.8919270e-05, 4.6164056e-05, 1.7459528e-06],\n",
       "                       [2.4998264e-04, 6.0210528e-04, 5.3803964e-05, ...,\n",
       "                        7.9205516e-04, 9.0860832e-04, 3.9966955e-05],\n",
       "                       ...,\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "  \n",
       "                      [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       ...,\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "                       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "                        0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[3.2258896e-07, 1.1797626e-06, 7.4201153e-06, ...,\n",
       "                       7.7869818e-06, 1.6049224e-06, 1.4837371e-05],\n",
       "                      [3.6355093e-06, 1.5907372e-06, 1.4986766e-06, ...,\n",
       "                       2.4479025e-06, 2.2622505e-06, 2.0287727e-05]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[1.9790891e-06, 4.1447828e-07, 2.3672499e-06, ...,\n",
       "                       1.2533143e-05, 1.1847892e-05, 2.2100523e-05],\n",
       "                      [2.9381131e-06, 1.1550428e-06, 1.2466886e-07, ...,\n",
       "                       1.2276319e-05, 1.5846774e-07, 4.0106756e-06]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[7.66096235e-08, 2.96959524e-08, 2.22572822e-08,\n",
       "                        ..., 2.76381904e-08, 1.99679207e-09,\n",
       "                        1.41496926e-07],\n",
       "                       [5.96460570e-09, 1.14566250e-08, 1.55181326e-08,\n",
       "                        ..., 1.56416050e-07, 9.12142895e-09,\n",
       "                        3.23876250e-08],\n",
       "                       [6.92446633e-09, 4.11599821e-08, 3.17542543e-08,\n",
       "                        ..., 1.01520570e-07, 9.51166612e-08,\n",
       "                        4.78691824e-08],\n",
       "                       ...,\n",
       "                       [7.19540560e-09, 3.99370350e-08, 1.08063233e-07,\n",
       "                        ..., 5.20856211e-08, 1.46034779e-07,\n",
       "                        9.77185444e-09],\n",
       "                       [2.09957154e-08, 1.59885403e-08, 7.58384715e-08,\n",
       "                        ..., 1.41735740e-07, 6.77301486e-08,\n",
       "                        3.58840202e-09],\n",
       "                       [1.97477945e-08, 7.33683603e-09, 4.21227355e-08,\n",
       "                        ..., 4.01102227e-08, 1.37305207e-07,\n",
       "                        1.92822576e-08]],\n",
       "  \n",
       "                      [[2.13309335e-08, 1.09236645e-07, 1.64455827e-08,\n",
       "                        ..., 1.42374104e-08, 4.59933034e-08,\n",
       "                        5.48171641e-08],\n",
       "                       [5.43654766e-09, 1.39938393e-07, 1.41536162e-07,\n",
       "                        ..., 6.60729160e-09, 1.55021223e-08,\n",
       "                        5.28787680e-08],\n",
       "                       [5.73309080e-08, 3.04240686e-08, 1.03976943e-08,\n",
       "                        ..., 8.21154078e-09, 3.73979745e-08,\n",
       "                        1.65239680e-08],\n",
       "                       ...,\n",
       "                       [7.28641325e-09, 2.31221282e-08, 6.96085278e-09,\n",
       "                        ..., 1.10989326e-07, 3.49134552e-08,\n",
       "                        6.17313811e-10],\n",
       "                       [1.28443801e-07, 2.21528129e-08, 3.76336118e-08,\n",
       "                        ..., 6.14069009e-08, 4.16270662e-09,\n",
       "                        1.10249916e-08],\n",
       "                       [1.19145383e-07, 2.33200453e-07, 4.31237268e-08,\n",
       "                        ..., 3.95813089e-08, 3.83780474e-08,\n",
       "                        6.68901805e-08]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[2.57797232e-08, 8.20863661e-08, 9.30397306e-08,\n",
       "                        ..., 4.58222580e-08, 4.00091835e-08,\n",
       "                        7.30771399e-09],\n",
       "                       [4.25714006e-08, 2.98925293e-08, 7.66249215e-08,\n",
       "                        ..., 5.21936734e-08, 8.99851749e-09,\n",
       "                        1.44449857e-08],\n",
       "                       [1.24901618e-08, 2.06373780e-08, 7.18914634e-08,\n",
       "                        ..., 9.43420009e-09, 1.13553673e-08,\n",
       "                        1.35647426e-07],\n",
       "                       ...,\n",
       "                       [1.71206231e-08, 1.66021394e-07, 7.46178586e-09,\n",
       "                        ..., 1.27112315e-07, 1.08880855e-07,\n",
       "                        9.94708245e-08],\n",
       "                       [3.72122351e-08, 6.09025648e-08, 1.47669468e-08,\n",
       "                        ..., 3.60356864e-08, 3.95587918e-08,\n",
       "                        8.00611346e-08],\n",
       "                       [4.62294913e-08, 6.00049148e-08, 1.07265112e-08,\n",
       "                        ..., 2.35639313e-08, 6.11844664e-09,\n",
       "                        6.00195023e-08]],\n",
       "  \n",
       "                      [[2.22337135e-08, 2.29114399e-08, 1.35724347e-08,\n",
       "                        ..., 9.12108344e-09, 2.89565669e-08,\n",
       "                        6.35009485e-08],\n",
       "                       [2.71956466e-08, 3.60398182e-08, 1.19475956e-07,\n",
       "                        ..., 7.54736096e-09, 5.98963936e-08,\n",
       "                        1.01725224e-08],\n",
       "                       [6.07306490e-08, 2.20348980e-07, 1.09604406e-08,\n",
       "                        ..., 1.57327218e-08, 2.33765576e-07,\n",
       "                        5.87898938e-08],\n",
       "                       ...,\n",
       "                       [2.79717955e-08, 1.78668557e-07, 1.58005435e-07,\n",
       "                        ..., 1.02080451e-08, 3.71020681e-09,\n",
       "                        2.80960109e-08],\n",
       "                       [4.86272000e-08, 3.36543593e-08, 2.00589305e-08,\n",
       "                        ..., 1.36217979e-08, 1.57018945e-07,\n",
       "                        1.44258934e-08],\n",
       "                       [3.60250532e-08, 1.46407420e-08, 9.93992177e-09,\n",
       "                        ..., 2.20763519e-09, 4.77625441e-08,\n",
       "                        2.43232687e-08]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[1.9462884e-07, 1.6133386e-07, 1.2500614e-07, ...,\n",
       "                        1.2484409e-07, 4.7168413e-08, 1.1884242e-07],\n",
       "                       [2.2388238e-07, 8.7875407e-08, 2.1077801e-08, ...,\n",
       "                        1.1875217e-07, 1.2380693e-07, 5.3736866e-08],\n",
       "                       [4.1030432e-08, 4.0331437e-07, 6.6532562e-07, ...,\n",
       "                        1.2842131e-08, 3.0186744e-08, 9.0562018e-08],\n",
       "                       ...,\n",
       "                       [1.0474752e-07, 1.7718519e-07, 2.7201099e-07, ...,\n",
       "                        6.3323689e-08, 5.2410383e-07, 2.6753790e-07],\n",
       "                       [7.9632629e-09, 7.4383602e-09, 1.9868385e-07, ...,\n",
       "                        1.9288422e-08, 1.9223997e-08, 4.5515949e-07],\n",
       "                       [6.2724149e-07, 1.6294246e-07, 4.1816978e-07, ...,\n",
       "                        6.8026822e-08, 3.0061793e-07, 4.4284729e-07]],\n",
       "  \n",
       "                      [[9.7370680e-08, 2.8802972e-08, 3.0117306e-07, ...,\n",
       "                        8.9651756e-08, 3.0551510e-07, 1.4568063e-07],\n",
       "                       [3.1861251e-07, 7.7325814e-07, 6.2180469e-08, ...,\n",
       "                        1.1165002e-08, 4.4275703e-07, 8.9652258e-07],\n",
       "                       [8.1196509e-07, 3.6386669e-07, 3.9837293e-08, ...,\n",
       "                        8.0881605e-08, 1.6394057e-07, 4.5102976e-07],\n",
       "                       ...,\n",
       "                       [5.0596287e-07, 1.0988829e-07, 1.2516914e-07, ...,\n",
       "                        3.8712503e-07, 1.0043863e-07, 7.0016296e-07],\n",
       "                       [1.3884310e-08, 1.6264231e-07, 2.8627608e-07, ...,\n",
       "                        8.1364341e-08, 1.4299268e-07, 8.7661114e-08],\n",
       "                       [7.3484273e-07, 3.9416673e-07, 3.5675660e-07, ...,\n",
       "                        2.3828553e-08, 1.4866019e-07, 2.7354369e-07]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[1.32401823e-07, 1.55021311e-07, 6.05822166e-08,\n",
       "                        ..., 1.47052594e-06, 6.68776456e-09,\n",
       "                        4.64678095e-07],\n",
       "                       [1.80699367e-08, 3.34674269e-07, 1.03990509e-07,\n",
       "                        ..., 1.95588271e-07, 3.44023533e-07,\n",
       "                        1.36458652e-07],\n",
       "                       [6.99273016e-07, 6.29197388e-08, 8.89014515e-08,\n",
       "                        ..., 1.38777834e-08, 6.06107221e-07,\n",
       "                        2.71749570e-07],\n",
       "                       ...,\n",
       "                       [1.21263426e-07, 3.50005365e-07, 1.75494748e-07,\n",
       "                        ..., 4.14690362e-08, 5.85661155e-08,\n",
       "                        1.80589538e-07],\n",
       "                       [6.84110262e-08, 2.98433136e-08, 7.05146732e-08,\n",
       "                        ..., 9.52302273e-08, 4.22542357e-08,\n",
       "                        9.08275624e-08],\n",
       "                       [3.85970282e-07, 2.58893607e-07, 2.24809270e-07,\n",
       "                        ..., 6.26609733e-08, 7.41742028e-08,\n",
       "                        2.04718134e-07]],\n",
       "  \n",
       "                      [[9.51867605e-07, 1.12433227e-07, 3.02868699e-07,\n",
       "                        ..., 1.05161888e-07, 5.62915488e-07,\n",
       "                        4.77465107e-07],\n",
       "                       [1.51163658e-06, 2.51468748e-07, 2.69451249e-07,\n",
       "                        ..., 5.72397880e-07, 9.54810560e-08,\n",
       "                        6.88240959e-07],\n",
       "                       [9.03997304e-08, 5.65784326e-08, 3.07786451e-07,\n",
       "                        ..., 8.24595858e-08, 3.22726237e-07,\n",
       "                        1.31173090e-06],\n",
       "                       ...,\n",
       "                       [8.52373248e-08, 8.08369691e-08, 2.80162293e-08,\n",
       "                        ..., 1.63038379e-07, 3.68602912e-07,\n",
       "                        4.25158987e-07],\n",
       "                       [2.90174171e-07, 4.17895990e-07, 1.08033554e-07,\n",
       "                        ..., 5.10689935e-09, 7.58866321e-08,\n",
       "                        1.28158661e-06],\n",
       "                       [4.91032665e-07, 3.22495254e-07, 2.41315892e-08,\n",
       "                        ..., 1.03946263e-07, 9.87602036e-08,\n",
       "                        1.07564563e-06]]], dtype=float32),\n",
       "  ShardedDeviceArray([[2.2465728e-07, 3.9177598e-07, 2.9104458e-06, ...,\n",
       "                       7.4976214e-07, 2.2592320e-07, 1.9470802e-07],\n",
       "                      [2.4222456e-06, 3.8252867e-07, 1.8169605e-06, ...,\n",
       "                       5.4905240e-07, 5.0036806e-07, 1.1715755e-06]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[2.27371331e-08, 1.31397326e-06, 1.23949303e-06,\n",
       "                        ..., 6.73885054e-08, 1.60916258e-07,\n",
       "                        2.80917135e-07],\n",
       "                       [1.58044191e-08, 7.23003836e-07, 8.35286542e-08,\n",
       "                        ..., 1.95093065e-07, 8.87605545e-09,\n",
       "                        2.53096403e-07],\n",
       "                       [1.80939907e-07, 1.04473195e-07, 2.14597776e-06,\n",
       "                        ..., 1.00971018e-08, 6.52825634e-07,\n",
       "                        9.65248773e-07],\n",
       "                       ...,\n",
       "                       [1.23680186e-08, 9.16440513e-07, 1.29882693e-07,\n",
       "                        ..., 6.99453608e-07, 3.34526473e-09,\n",
       "                        4.44304504e-07],\n",
       "                       [4.20833800e-07, 8.90340687e-07, 2.84618636e-07,\n",
       "                        ..., 2.71768897e-07, 7.13535826e-07,\n",
       "                        3.87341061e-06],\n",
       "                       [5.79703645e-08, 6.62712182e-07, 2.10684341e-08,\n",
       "                        ..., 1.61821305e-07, 3.41290047e-07,\n",
       "                        1.67226563e-06]],\n",
       "  \n",
       "                      [[2.30233397e-07, 8.74925288e-09, 1.95343674e-07,\n",
       "                        ..., 4.58967094e-07, 2.74560481e-08,\n",
       "                        1.28672411e-07],\n",
       "                       [1.13070378e-07, 2.69159699e-08, 1.44901421e-07,\n",
       "                        ..., 6.10794118e-08, 6.19042339e-07,\n",
       "                        1.55707210e-06],\n",
       "                       [1.25676280e-07, 2.12236742e-07, 9.76204092e-07,\n",
       "                        ..., 7.33839329e-07, 9.21939947e-09,\n",
       "                        1.25964021e-07],\n",
       "                       ...,\n",
       "                       [3.75648938e-06, 3.26447605e-07, 3.21289697e-08,\n",
       "                        ..., 1.56909471e-06, 1.01373708e-07,\n",
       "                        1.64358113e-07],\n",
       "                       [6.38662172e-08, 4.42320425e-06, 1.59010909e-07,\n",
       "                        ..., 5.05782737e-06, 3.18423474e-08,\n",
       "                        9.40097689e-09],\n",
       "                       [1.25775296e-06, 2.64918008e-08, 4.87611942e-07,\n",
       "                        ..., 1.73327680e-06, 8.96592027e-08,\n",
       "                        6.85174939e-08]]], dtype=float32),\n",
       "  ShardedDeviceArray([[2.4665953e-06, 9.1489835e-07, 1.9695733e-06, ...,\n",
       "                       1.6194739e-06, 4.2606853e-06, 1.0912295e-05],\n",
       "                      [2.4665953e-06, 9.1489835e-07, 1.9695733e-06, ...,\n",
       "                       1.6194739e-06, 4.2606853e-06, 1.0912295e-05]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[1.10393194e-06, 2.97306464e-08, 3.34931997e-07,\n",
       "                        ..., 9.94452520e-08, 2.54572200e-07,\n",
       "                        2.49265838e-07],\n",
       "                       [2.78967991e-06, 2.20279139e-06, 9.42901579e-08,\n",
       "                        ..., 1.90989581e-07, 6.17339140e-07,\n",
       "                        1.35409357e-06],\n",
       "                       [1.12560826e-06, 4.84817292e-07, 3.55841593e-07,\n",
       "                        ..., 1.55629976e-07, 2.18550852e-07,\n",
       "                        1.18479841e-06],\n",
       "                       ...,\n",
       "                       [4.22018296e-08, 5.42854339e-09, 1.01971909e-06,\n",
       "                        ..., 2.99947601e-07, 4.60754990e-08,\n",
       "                        2.02165012e-07],\n",
       "                       [1.41596828e-07, 1.29311829e-07, 5.09090967e-07,\n",
       "                        ..., 1.14630609e-07, 8.45680916e-07,\n",
       "                        1.94104004e-07],\n",
       "                       [1.00351095e-07, 2.65364861e-07, 3.06846800e-07,\n",
       "                        ..., 4.08901784e-08, 2.16348809e-07,\n",
       "                        1.54598592e-06]],\n",
       "  \n",
       "                      [[1.40131329e-08, 3.13174723e-06, 7.25441282e-07,\n",
       "                        ..., 2.25773647e-07, 1.35478729e-07,\n",
       "                        4.52373911e-07],\n",
       "                       [1.20885829e-06, 6.35868503e-07, 1.15132543e-07,\n",
       "                        ..., 1.70506581e-07, 4.36392007e-08,\n",
       "                        2.01438070e-07],\n",
       "                       [1.39392981e-07, 3.19720755e-07, 2.07023004e-06,\n",
       "                        ..., 7.76102979e-07, 2.96549842e-07,\n",
       "                        1.75579294e-06],\n",
       "                       ...,\n",
       "                       [7.37136872e-07, 6.98106390e-08, 1.19868355e-06,\n",
       "                        ..., 2.87086635e-07, 1.62841243e-08,\n",
       "                        6.92371742e-08],\n",
       "                       [8.97804000e-08, 1.04805018e-07, 1.60949298e-08,\n",
       "                        ..., 1.38377354e-08, 1.69139327e-07,\n",
       "                        5.29630199e-07],\n",
       "                       [1.16746628e-06, 5.89049236e-08, 9.04676767e-07,\n",
       "                        ..., 2.32030253e-08, 9.43066780e-08,\n",
       "                        1.93893675e-06]]], dtype=float32),\n",
       "  ShardedDeviceArray([[4.7855571e-07, 1.1847462e-06, 1.6225882e-06, ...,\n",
       "                       2.6376719e-07, 8.9847468e-08, 2.3847949e-06],\n",
       "                      [2.9438092e-06, 1.1627177e-06, 9.8401597e-07, ...,\n",
       "                       1.4469593e-07, 3.6633942e-06, 3.9116389e-06]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[5.6433362e-07, 1.4588822e-07, 1.0449023e-06, ...,\n",
       "                       6.4465473e-07, 8.7624926e-08, 8.7309012e-08],\n",
       "                      [3.0957997e-07, 8.6581309e-07, 1.7780122e-06, ...,\n",
       "                       3.0409906e-06, 2.4108436e-07, 6.7735948e-07]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[1.19942598e-08, 4.40341736e-08, 6.15499118e-08,\n",
       "                        ..., 4.51029152e-08, 3.46964435e-09,\n",
       "                        7.38121519e-09],\n",
       "                       [6.10776940e-09, 8.66864447e-09, 5.06280529e-09,\n",
       "                        ..., 6.69755895e-09, 1.73155623e-08,\n",
       "                        3.39642137e-09],\n",
       "                       [4.01984082e-08, 5.14517717e-09, 2.51200785e-08,\n",
       "                        ..., 1.18469909e-08, 6.42400844e-09,\n",
       "                        1.00551247e-08],\n",
       "                       ...,\n",
       "                       [5.43179057e-09, 9.49644807e-09, 1.26184547e-08,\n",
       "                        ..., 4.06170919e-09, 9.64104263e-09,\n",
       "                        3.65960284e-09],\n",
       "                       [1.54001469e-08, 2.94801410e-08, 3.24494778e-08,\n",
       "                        ..., 5.95773608e-09, 1.08164123e-07,\n",
       "                        7.46248663e-09],\n",
       "                       [4.38575931e-09, 6.25035890e-09, 2.03264672e-09,\n",
       "                        ..., 7.93989940e-09, 4.73484825e-08,\n",
       "                        5.42999468e-09]],\n",
       "  \n",
       "                      [[4.80802020e-09, 3.66135966e-09, 1.54555266e-08,\n",
       "                        ..., 5.87191495e-09, 7.50244755e-09,\n",
       "                        1.21839400e-10],\n",
       "                       [8.29770475e-09, 1.00286632e-08, 1.47670347e-08,\n",
       "                        ..., 2.72420273e-08, 8.42302228e-09,\n",
       "                        5.70139214e-10],\n",
       "                       [5.33631583e-09, 1.10948772e-09, 1.33997913e-09,\n",
       "                        ..., 5.66739411e-09, 7.08263004e-09,\n",
       "                        2.96930325e-09],\n",
       "                       ...,\n",
       "                       [3.31666139e-09, 1.96943084e-08, 1.50967008e-08,\n",
       "                        ..., 9.82891990e-09, 2.80024199e-08,\n",
       "                        2.15428120e-08],\n",
       "                       [3.68945874e-09, 2.55987018e-08, 9.12965081e-09,\n",
       "                        ..., 3.74322795e-08, 1.11995195e-08,\n",
       "                        6.17978557e-09],\n",
       "                       [1.32375122e-09, 2.92349234e-09, 3.14772430e-09,\n",
       "                        ..., 7.34055616e-09, 1.31535991e-08,\n",
       "                        1.13903971e-08]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[7.5051034e-08, 6.0936745e-09, 6.7793455e-09, ...,\n",
       "                        1.3550143e-08, 7.0395614e-09, 1.1966778e-09],\n",
       "                       [1.0225750e-09, 3.5003751e-09, 5.3402838e-09, ...,\n",
       "                        2.0878943e-09, 2.1824869e-09, 3.0356533e-09],\n",
       "                       [1.6473559e-08, 9.9263584e-09, 9.8055235e-09, ...,\n",
       "                        3.0450116e-09, 1.7450219e-08, 2.9179379e-09],\n",
       "                       ...,\n",
       "                       [1.2451104e-08, 7.3626808e-08, 3.6588030e-08, ...,\n",
       "                        3.2058758e-09, 2.5715076e-08, 6.2531251e-09],\n",
       "                       [3.1020686e-08, 2.4603445e-08, 2.9714664e-09, ...,\n",
       "                        1.1544504e-08, 1.2680938e-08, 5.7380700e-09],\n",
       "                       [7.3267529e-08, 7.2571509e-09, 9.2039336e-09, ...,\n",
       "                        4.5651483e-09, 1.3651214e-08, 1.5464338e-09]],\n",
       "  \n",
       "                      [[2.6566989e-09, 2.9263523e-09, 4.1299120e-09, ...,\n",
       "                        2.5589653e-08, 2.9937373e-09, 7.9083484e-10],\n",
       "                       [1.3912714e-08, 3.7481463e-08, 1.2037629e-08, ...,\n",
       "                        8.8066421e-10, 9.5323758e-09, 7.5199580e-09],\n",
       "                       [6.1172756e-09, 6.8411405e-09, 5.1872640e-09, ...,\n",
       "                        3.9229797e-09, 9.0734487e-09, 3.2237079e-08],\n",
       "                       ...,\n",
       "                       [4.9808295e-09, 2.7285396e-09, 1.8853965e-09, ...,\n",
       "                        2.4416599e-08, 1.5791868e-09, 9.1005603e-09],\n",
       "                       [3.8511164e-10, 1.6635239e-09, 4.9360183e-10, ...,\n",
       "                        3.4537810e-09, 1.0413508e-08, 1.3317907e-09],\n",
       "                       [3.9605004e-09, 4.4855346e-09, 6.4575030e-09, ...,\n",
       "                        9.9215800e-09, 3.1952843e-09, 1.9932010e-08]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[2.06884483e-08, 3.53497853e-08, 5.98062888e-09,\n",
       "                        ..., 6.39715267e-08, 1.24213129e-08,\n",
       "                        2.31909389e-08],\n",
       "                       [2.82859727e-08, 1.50111333e-07, 3.16644275e-08,\n",
       "                        ..., 1.99348840e-08, 1.93719316e-07,\n",
       "                        9.32729733e-08],\n",
       "                       [2.70116161e-08, 8.25858066e-08, 1.31589015e-08,\n",
       "                        ..., 1.28204718e-07, 1.06561142e-08,\n",
       "                        2.01744896e-08],\n",
       "                       ...,\n",
       "                       [2.34730152e-07, 4.24284963e-08, 2.50367886e-08,\n",
       "                        ..., 2.85635284e-08, 1.41538280e-07,\n",
       "                        3.29136824e-08],\n",
       "                       [8.58582467e-08, 3.70131992e-09, 1.27161099e-08,\n",
       "                        ..., 2.53313317e-08, 5.65013103e-09,\n",
       "                        2.18608385e-08],\n",
       "                       [9.51801571e-09, 4.33244267e-08, 9.03845958e-08,\n",
       "                        ..., 1.82156128e-07, 1.01997536e-07,\n",
       "                        1.13369323e-08]],\n",
       "  \n",
       "                      [[2.46362049e-07, 1.13942509e-08, 6.71085445e-08,\n",
       "                        ..., 1.24257511e-08, 3.74106577e-07,\n",
       "                        1.35693581e-08],\n",
       "                       [2.07732469e-07, 9.60406421e-09, 8.12997953e-08,\n",
       "                        ..., 1.03739115e-08, 6.76960212e-08,\n",
       "                        1.15539308e-07],\n",
       "                       [1.58305056e-07, 5.88632361e-08, 2.11642075e-07,\n",
       "                        ..., 7.11620673e-09, 7.36201073e-08,\n",
       "                        4.53682354e-08],\n",
       "                       ...,\n",
       "                       [6.73585347e-08, 6.13223463e-08, 1.44396253e-07,\n",
       "                        ..., 1.17286882e-08, 2.33870296e-07,\n",
       "                        1.46488887e-07],\n",
       "                       [1.12886518e-07, 3.42203910e-09, 3.18945759e-08,\n",
       "                        ..., 8.13121517e-08, 1.30982471e-07,\n",
       "                        8.88364156e-08],\n",
       "                       [2.87435107e-08, 7.17670900e-08, 2.26280278e-07,\n",
       "                        ..., 2.90364444e-08, 1.92279060e-07,\n",
       "                        4.07403533e-08]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[1.0615883e-08, 5.9259605e-08, 3.2608114e-08, ...,\n",
       "                        7.3932316e-10, 1.8998374e-08, 2.2265608e-08],\n",
       "                       [3.7253592e-08, 1.1787880e-07, 6.0626002e-09, ...,\n",
       "                        4.4520604e-08, 6.8146214e-08, 9.2205806e-07],\n",
       "                       [8.9410586e-09, 4.3856292e-09, 1.9862364e-08, ...,\n",
       "                        2.1180606e-08, 2.8632602e-08, 6.2483217e-08],\n",
       "                       ...,\n",
       "                       [4.3964675e-07, 5.4737438e-08, 6.0564055e-08, ...,\n",
       "                        3.7145116e-07, 2.1684750e-07, 2.2518110e-07],\n",
       "                       [5.7893391e-08, 1.5351308e-07, 1.9458895e-08, ...,\n",
       "                        8.5099581e-09, 1.8339561e-08, 3.1509151e-07],\n",
       "                       [2.2986715e-07, 2.7678841e-08, 1.9114109e-08, ...,\n",
       "                        6.7666247e-07, 1.6611024e-08, 3.9243304e-07]],\n",
       "  \n",
       "                      [[7.6692785e-09, 1.9734244e-08, 7.9242540e-08, ...,\n",
       "                        7.4443776e-08, 4.8824809e-08, 8.8279037e-08],\n",
       "                       [1.1327975e-07, 1.5290723e-07, 4.3800931e-08, ...,\n",
       "                        1.8419207e-07, 4.5107804e-08, 5.7412046e-07],\n",
       "                       [1.0171413e-07, 1.5688876e-08, 1.1055754e-08, ...,\n",
       "                        5.6235098e-08, 2.4688179e-08, 6.3683473e-08],\n",
       "                       ...,\n",
       "                       [6.9684916e-08, 2.5819885e-08, 4.6639943e-08, ...,\n",
       "                        1.6512056e-08, 1.4707724e-08, 8.6358334e-08],\n",
       "                       [8.6722281e-08, 9.4672989e-09, 3.3265980e-08, ...,\n",
       "                        5.7863780e-08, 8.1360589e-08, 1.3113332e-07],\n",
       "                       [1.2160115e-07, 4.0272962e-08, 1.0666219e-08, ...,\n",
       "                        1.2591636e-08, 3.7635555e-08, 2.0608175e-08]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[1.7773765e-07, 1.1767422e-07, 4.7200125e-08, ...,\n",
       "                       2.3917107e-07, 1.0871911e-07, 2.3986982e-07],\n",
       "                      [4.5162196e-07, 5.0879987e-07, 1.5936010e-07, ...,\n",
       "                       8.6716447e-08, 3.4665764e-08, 4.4125439e-08]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[5.69886005e-08, 3.38361659e-08, 3.29058281e-07,\n",
       "                        ..., 2.37852831e-07, 2.37903009e-07,\n",
       "                        1.25809976e-08],\n",
       "                       [1.93110594e-08, 1.61919900e-07, 1.46013960e-07,\n",
       "                        ..., 1.50773317e-07, 5.80628921e-07,\n",
       "                        1.52537311e-07],\n",
       "                       [3.90858560e-07, 6.92619428e-09, 1.87706320e-07,\n",
       "                        ..., 2.00624768e-07, 1.89518488e-07,\n",
       "                        4.22569713e-08],\n",
       "                       ...,\n",
       "                       [3.68616156e-07, 1.03548858e-08, 6.61154047e-08,\n",
       "                        ..., 5.19982635e-08, 2.44064552e-07,\n",
       "                        7.60192478e-08],\n",
       "                       [6.37623145e-08, 1.96216618e-07, 4.95569168e-08,\n",
       "                        ..., 9.52757304e-08, 3.56800172e-07,\n",
       "                        2.16945978e-07],\n",
       "                       [3.18330713e-08, 1.81767277e-07, 3.44502276e-08,\n",
       "                        ..., 1.90795948e-08, 1.87882762e-07,\n",
       "                        4.11334241e-07]],\n",
       "  \n",
       "                      [[8.38456486e-08, 3.13914263e-08, 3.17224913e-09,\n",
       "                        ..., 5.45875096e-08, 2.56260449e-07,\n",
       "                        9.00598920e-08],\n",
       "                       [3.74394098e-08, 5.43375194e-08, 1.28816893e-07,\n",
       "                        ..., 8.18960899e-09, 9.59325419e-08,\n",
       "                        1.28064073e-07],\n",
       "                       [2.23843450e-08, 2.00220896e-07, 3.53049430e-08,\n",
       "                        ..., 6.13261086e-09, 4.03776603e-08,\n",
       "                        2.15959332e-07],\n",
       "                       ...,\n",
       "                       [1.31283535e-08, 6.51098446e-07, 1.62214526e-08,\n",
       "                        ..., 5.75762833e-08, 1.02555788e-07,\n",
       "                        7.00457576e-08],\n",
       "                       [5.95222843e-07, 5.81484983e-07, 4.84441891e-08,\n",
       "                        ..., 1.25127544e-08, 5.28730993e-07,\n",
       "                        3.14539960e-07],\n",
       "                       [7.56359668e-08, 2.51256807e-07, 1.50242869e-07,\n",
       "                        ..., 2.23918715e-08, 1.31901290e-08,\n",
       "                        4.76504454e-07]]], dtype=float32),\n",
       "  ShardedDeviceArray([[5.1794683e-07, 4.0968970e-08, 2.7773362e-07, ...,\n",
       "                       1.0248785e-06, 1.2059063e-06, 3.1660966e-06],\n",
       "                      [5.1794683e-07, 4.0968970e-08, 2.7773362e-07, ...,\n",
       "                       1.0248785e-06, 1.2059063e-06, 3.1660966e-06]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[7.29652117e-09, 9.09704312e-09, 5.54432678e-09,\n",
       "                        ..., 1.11413598e-08, 3.35963501e-09,\n",
       "                        3.80051226e-08],\n",
       "                       [4.59013663e-08, 3.92658528e-08, 4.79538791e-08,\n",
       "                        ..., 5.61324232e-09, 1.68182677e-08,\n",
       "                        1.01770631e-07],\n",
       "                       [6.95087806e-07, 2.75390505e-07, 9.47721972e-08,\n",
       "                        ..., 3.13543723e-07, 3.57507659e-08,\n",
       "                        1.51184736e-07],\n",
       "                       ...,\n",
       "                       [3.32664065e-08, 2.42693829e-07, 3.43405873e-07,\n",
       "                        ..., 3.51421363e-08, 3.89950145e-07,\n",
       "                        4.25994017e-07],\n",
       "                       [1.03049445e-07, 3.47291149e-07, 4.10386178e-08,\n",
       "                        ..., 3.09395567e-08, 4.09648102e-08,\n",
       "                        1.25551409e-07],\n",
       "                       [5.13373735e-08, 9.20412845e-07, 5.10106233e-08,\n",
       "                        ..., 6.40522160e-07, 2.35967335e-08,\n",
       "                        8.49574462e-07]],\n",
       "  \n",
       "                      [[4.19776995e-08, 5.39142171e-08, 7.77609230e-08,\n",
       "                        ..., 1.10403908e-08, 6.66329925e-08,\n",
       "                        7.71086590e-08],\n",
       "                       [5.00855322e-07, 6.46960174e-09, 1.11378675e-07,\n",
       "                        ..., 5.17175769e-09, 2.07459863e-08,\n",
       "                        5.04683904e-08],\n",
       "                       [1.79692222e-07, 1.15581820e-08, 5.64250335e-08,\n",
       "                        ..., 2.19325315e-07, 3.64792072e-08,\n",
       "                        2.32896312e-07],\n",
       "                       ...,\n",
       "                       [2.22854808e-07, 1.00221932e-07, 1.76649948e-07,\n",
       "                        ..., 8.21201297e-07, 3.61938675e-07,\n",
       "                        1.97150474e-08],\n",
       "                       [4.77219686e-09, 1.80188067e-07, 1.70876334e-07,\n",
       "                        ..., 9.49765635e-08, 3.92909811e-08,\n",
       "                        7.86912651e-08],\n",
       "                       [5.68480942e-08, 2.19497608e-07, 6.08845028e-08,\n",
       "                        ..., 1.29465889e-07, 1.14240834e-06,\n",
       "                        3.37117672e-06]]], dtype=float32),\n",
       "  ShardedDeviceArray([[1.3536392e-05, 7.5490789e-07, 1.2628241e-05, ...,\n",
       "                       3.6376594e-05, 2.6764272e-05, 6.6414315e-05],\n",
       "                      [3.9706741e-08, 5.8854215e-07, 1.1002276e-07, ...,\n",
       "                       5.7603012e-07, 4.9203305e-08, 3.3980675e-07]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[1.7471042e-05, 3.3912205e-05, 2.6912534e-05, ...,\n",
       "                       8.6917556e-05, 2.4265830e-05, 2.0252517e-05],\n",
       "                      [2.5266058e-07, 2.1288498e-08, 2.7081970e-07, ...,\n",
       "                       2.8289725e-07, 1.4667012e-07, 4.1410029e-08]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[4.5202378e-05, 6.0492795e-05, 4.5886930e-04, ...,\n",
       "                       4.1142133e-07, 5.1926236e-07, 4.7152682e-07],\n",
       "                      [8.3122853e-07, 4.8694699e-07, 3.8324345e-07, ...,\n",
       "                       2.3241751e-07, 4.1183569e-07, 1.2336370e-06]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[1.7649440e-07, 2.8172142e-05, 1.1163848e-04, ...,\n",
       "                        1.0232201e-08, 1.7886773e-08, 2.9529811e-08],\n",
       "                       [1.8060900e-05, 3.6594134e-05, 9.7656566e-06, ...,\n",
       "                        3.1131957e-08, 1.3950073e-08, 1.8570373e-07],\n",
       "                       [8.1586732e-06, 5.4924044e-06, 2.5256467e-04, ...,\n",
       "                        4.0490878e-08, 3.1579674e-07, 9.2562935e-08],\n",
       "                       ...,\n",
       "                       [1.2485185e-04, 1.2734476e-04, 3.2136738e-04, ...,\n",
       "                        2.7616544e-08, 2.8673544e-08, 1.1843148e-08],\n",
       "                       [1.3164914e-05, 5.7860034e-06, 2.2842058e-05, ...,\n",
       "                        2.9083251e-08, 2.6648125e-08, 3.9657351e-08],\n",
       "                       [2.0615569e-04, 1.6141319e-05, 3.2421078e-05, ...,\n",
       "                        1.8036579e-07, 6.8018153e-08, 1.4052820e-07]],\n",
       "  \n",
       "                      [[7.8952688e-08, 1.3461498e-08, 2.7120148e-08, ...,\n",
       "                        9.4874757e-09, 1.0939643e-08, 1.1242845e-07],\n",
       "                       [9.7401049e-08, 7.7204362e-08, 5.0266049e-08, ...,\n",
       "                        3.3119374e-08, 2.1899199e-08, 7.4240660e-08],\n",
       "                       [1.8770898e-07, 5.8806023e-08, 8.3046352e-08, ...,\n",
       "                        4.3049418e-08, 8.0767691e-08, 3.1052741e-07],\n",
       "                       ...,\n",
       "                       [1.4178501e-08, 1.1742357e-08, 6.3105404e-08, ...,\n",
       "                        7.3378490e-09, 6.3061236e-09, 2.0677794e-07],\n",
       "                       [3.9690089e-08, 2.6015735e-08, 3.7404192e-08, ...,\n",
       "                        1.8305899e-08, 2.6640846e-08, 9.0342411e-08],\n",
       "                       [2.3807554e-07, 1.0494340e-07, 1.1201321e-07, ...,\n",
       "                        4.2484640e-08, 8.1116497e-08, 4.1479512e-07]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-0.02197604, -0.01533023, -0.03266641, ...,\n",
       "                         0.0124519 ,  0.0099805 , -0.01562884],\n",
       "                       [-0.00773637, -0.01555788, -0.01927066, ...,\n",
       "                        -0.02168661, -0.00723228,  0.00212037],\n",
       "                       [-0.01269526, -0.00774978, -0.00119767, ...,\n",
       "                         0.00360265, -0.00043027,  0.02806898],\n",
       "                       ...,\n",
       "                       [ 0.02262986,  0.01205044,  0.00293062, ...,\n",
       "                        -0.01984305, -0.00528912,  0.01278742],\n",
       "                       [ 0.01985458,  0.00325407,  0.0197254 , ...,\n",
       "                        -0.0323686 , -0.01542025,  0.00097761],\n",
       "                       [ 0.00827295, -0.01658025, -0.01731617, ...,\n",
       "                        -0.01637102, -0.00894194,  0.01233066]],\n",
       "  \n",
       "                      [[-0.00202305,  0.02205676, -0.00574691, ...,\n",
       "                         0.02315267, -0.00824713,  0.01801521],\n",
       "                       [ 0.00104228,  0.00053835, -0.00903931, ...,\n",
       "                         0.00602075,  0.01056694,  0.01321219],\n",
       "                       [ 0.01685287,  0.02065684,  0.00926371, ...,\n",
       "                         0.0022488 ,  0.00055682,  0.0281587 ],\n",
       "                       ...,\n",
       "                       [-0.00963914,  0.02503172,  0.00778428, ...,\n",
       "                         0.00701605, -0.02301247, -0.03067823],\n",
       "                       [-0.02646727,  0.0039724 , -0.03138046, ...,\n",
       "                        -0.00200577,  0.00150496,  0.01248406],\n",
       "                       [-0.02335673, -0.02985091,  0.0093748 , ...,\n",
       "                         0.01085868,  0.01264717, -0.00175391]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00050999,  0.00068268,  0.00074501, ...,\n",
       "                       -0.00056544, -0.00068719,  0.00049796],\n",
       "                      [-0.00050999,  0.00068268,  0.00074501, ...,\n",
       "                       -0.00056544, -0.00068719,  0.00049796]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.00619699,  0.01688645, -0.00535017, ...,\n",
       "                         0.00036708, -0.00066066,  0.02069691],\n",
       "                       [ 0.00236892,  0.01460883, -0.01538324, ...,\n",
       "                        -0.00716945, -0.01487156,  0.00379402],\n",
       "                       [ 0.01071384, -0.01087267, -0.00967039, ...,\n",
       "                        -0.00501179, -0.00603375, -0.01336232],\n",
       "                       ...,\n",
       "                       [ 0.00559579, -0.02009062, -0.00680667, ...,\n",
       "                         0.00453098,  0.00420304,  0.01687386],\n",
       "                       [-0.01109369, -0.0109405 ,  0.01599009, ...,\n",
       "                         0.00082599,  0.01074328,  0.02790227],\n",
       "                       [-0.00420856, -0.01350597, -0.0220648 , ...,\n",
       "                        -0.00500628, -0.01475686,  0.00802305]],\n",
       "  \n",
       "                      [[ 0.01746087, -0.01278617, -0.00556213, ...,\n",
       "                         0.00154901,  0.0145951 ,  0.00538669],\n",
       "                       [ 0.00989354,  0.00809569, -0.00941049, ...,\n",
       "                        -0.00554169,  0.01194227,  0.00841806],\n",
       "                       [ 0.00625336, -0.00060499, -0.00695647, ...,\n",
       "                        -0.00097865,  0.00679557,  0.00509065],\n",
       "                       ...,\n",
       "                       [ 0.00501728,  0.01250712,  0.02343217, ...,\n",
       "                        -0.00175554, -0.01373858,  0.00523915],\n",
       "                       [ 0.00907523,  0.00186812,  0.00272729, ...,\n",
       "                         0.01720096, -0.00144052, -0.01337374],\n",
       "                       [ 0.01580713, -0.01050735, -0.02114743, ...,\n",
       "                        -0.00032908, -0.00820684,  0.01416586]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-9.6992189e-05,  6.0590456e-04,  6.2719319e-04, ...,\n",
       "                       -5.2846869e-04, -6.6821522e-04,  4.1346770e-04],\n",
       "                      [-6.0689740e-04,  7.1388285e-04,  1.2279038e-04, ...,\n",
       "                       -6.2935753e-04, -6.9595070e-04,  5.6805398e-04]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[0.9993122 , 1.0001205 , 0.9992809 , ..., 1.0007504 ,\n",
       "                       0.99927634, 0.9992544 ],\n",
       "                      [0.9992794 , 1.0007442 , 1.0006524 , ..., 1.0007089 ,\n",
       "                       1.000112  , 0.99930185]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.03122558,  0.01088259,  0.0103282 , ...,\n",
       "                         0.01253718,  0.01810544,  0.00090563],\n",
       "                       [-0.00107301, -0.00603229, -0.00091623, ...,\n",
       "                        -0.01760996, -0.0092982 , -0.00657742],\n",
       "                       [ 0.01165611, -0.00777143,  0.02744025, ...,\n",
       "                         0.00538612, -0.01456671, -0.00169183],\n",
       "                       ...,\n",
       "                       [-0.01296772,  0.00891377,  0.01410855, ...,\n",
       "                        -0.00899769, -0.00240908,  0.00662817],\n",
       "                       [ 0.00153138,  0.00268833,  0.02479417, ...,\n",
       "                        -0.00619899,  0.01203935,  0.00397922],\n",
       "                       [ 0.00634188,  0.01435639, -0.01012363, ...,\n",
       "                         0.0212426 , -0.01563903, -0.0056361 ]],\n",
       "  \n",
       "                      [[-0.01586572, -0.01092203,  0.03286624, ...,\n",
       "                        -0.03196009, -0.00560292,  0.01557757],\n",
       "                       [ 0.0071278 , -0.0201143 , -0.02393739, ...,\n",
       "                        -0.02228498, -0.00882566, -0.00280373],\n",
       "                       [-0.03522353, -0.02174394, -0.01348842, ...,\n",
       "                         0.01874577,  0.00128006, -0.01474895],\n",
       "                       ...,\n",
       "                       [ 0.00427817,  0.00707025,  0.03121874, ...,\n",
       "                         0.0187868 ,  0.00013835,  0.00074322],\n",
       "                       [-0.00360903,  0.00235233,  0.00489789, ...,\n",
       "                         0.01629767,  0.00472789,  0.00737949],\n",
       "                       [ 0.00239603, -0.00922838, -0.01150822, ...,\n",
       "                         0.01611098, -0.00206584,  0.01181597]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.01512159,  0.00944429, -0.01222693, ...,\n",
       "                         0.01193721, -0.00278004,  0.01446396],\n",
       "                       [ 0.01040902, -0.00368728,  0.02963591, ...,\n",
       "                         0.00060195,  0.00744128, -0.02027826],\n",
       "                       [ 0.02011615, -0.02509696,  0.00216417, ...,\n",
       "                         0.01022648, -0.00083094, -0.01067512],\n",
       "                       ...,\n",
       "                       [ 0.03216255, -0.00407111,  0.02513664, ...,\n",
       "                         0.0156381 , -0.00567637, -0.02087764],\n",
       "                       [-0.00736896,  0.00647887, -0.00695577, ...,\n",
       "                        -0.00838298,  0.00225764,  0.00074556],\n",
       "                       [ 0.00408106,  0.00028169,  0.02930696, ...,\n",
       "                         0.00519842,  0.01023757, -0.0317206 ]],\n",
       "  \n",
       "                      [[-0.01083382, -0.00848235,  0.02575061, ...,\n",
       "                         0.00196364,  0.00019563,  0.02360115],\n",
       "                       [-0.01069839, -0.00514616, -0.01654064, ...,\n",
       "                        -0.01798812, -0.02056709, -0.0116022 ],\n",
       "                       [ 0.00602757, -0.00860233, -0.0007742 , ...,\n",
       "                         0.02077491, -0.00438728, -0.01360449],\n",
       "                       ...,\n",
       "                       [-0.03391316,  0.02381115, -0.00858515, ...,\n",
       "                         0.01020195,  0.00393362, -0.01620434],\n",
       "                       [ 0.02413209, -0.00714436,  0.02642096, ...,\n",
       "                        -0.00987934,  0.00293584,  0.00164918],\n",
       "                       [-0.00739401,  0.01622942, -0.0019509 , ...,\n",
       "                        -0.00315715,  0.03318014, -0.02998037]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-2.6754554e-02, -1.8023079e-02,  7.0121665e-03,\n",
       "                        ..., -2.7032098e-02,  9.1819037e-03,\n",
       "                         1.8024288e-02],\n",
       "                       [-1.5604173e-02, -3.0747663e-02, -3.1433206e-05,\n",
       "                        ..., -9.9466098e-03,  1.7137472e-02,\n",
       "                         1.3030180e-02],\n",
       "                       [ 5.9314133e-03,  1.7899683e-02,  1.3300769e-02,\n",
       "                        ...,  1.1980005e-03,  1.6657030e-02,\n",
       "                        -4.1742949e-03],\n",
       "                       ...,\n",
       "                       [ 2.3889830e-02,  3.3070926e-02,  2.3768583e-02,\n",
       "                        ...,  1.0457602e-02,  1.7135868e-02,\n",
       "                        -1.3828197e-02],\n",
       "                       [ 1.2277758e-02, -3.4672864e-02,  4.0590507e-03,\n",
       "                        ...,  1.6183605e-02, -8.5777249e-03,\n",
       "                        -2.0657118e-02],\n",
       "                       [ 2.8418167e-02, -7.4229115e-03,  1.7175935e-03,\n",
       "                        ..., -7.9444852e-03,  5.0671166e-03,\n",
       "                         7.2395229e-03]],\n",
       "  \n",
       "                      [[ 2.4945537e-02,  2.2265507e-02,  5.9924754e-03,\n",
       "                        ...,  1.7004630e-02,  8.7152384e-03,\n",
       "                        -8.7788710e-03],\n",
       "                       [ 4.4443691e-03, -3.6161344e-03,  1.3598995e-02,\n",
       "                        ...,  1.7810402e-02, -2.5079487e-02,\n",
       "                         1.9971242e-02],\n",
       "                       [-1.8972553e-03,  7.9476396e-03, -1.9967074e-02,\n",
       "                        ...,  7.1201231e-03, -1.3601817e-02,\n",
       "                        -4.0041339e-03],\n",
       "                       ...,\n",
       "                       [-2.5070567e-02,  9.8763211e-03, -6.5420996e-03,\n",
       "                        ..., -1.6548743e-02,  1.1500186e-02,\n",
       "                         1.4626939e-02],\n",
       "                       [-2.8701946e-02,  2.3402805e-02,  1.0151401e-02,\n",
       "                        ..., -1.0764418e-03, -2.0552468e-02,\n",
       "                        -5.0759600e-03],\n",
       "                       [ 4.5598759e-03,  2.3812035e-02, -1.2834396e-02,\n",
       "                        ...,  2.2803385e-02,  6.8984260e-03,\n",
       "                        -1.5016555e-02]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.02273825, -0.00650981,  0.0077765 , ...,\n",
       "                        -0.00807643,  0.00690298, -0.03245695],\n",
       "                       [-0.00548544, -0.00613181, -0.01688758, ...,\n",
       "                         0.01728293,  0.02550615,  0.00773131],\n",
       "                       [ 0.01812469, -0.00631093,  0.02084181, ...,\n",
       "                         0.0278648 , -0.00842835,  0.02096793],\n",
       "                       ...,\n",
       "                       [ 0.01723375, -0.00087158, -0.02675154, ...,\n",
       "                         0.00360387,  0.00579772,  0.01265726],\n",
       "                       [-0.00453705, -0.01302435, -0.00388504, ...,\n",
       "                        -0.00152485, -0.00031821, -0.01062997],\n",
       "                       [-0.00692374, -0.00474913,  0.00922594, ...,\n",
       "                         0.02901065, -0.0120532 , -0.02905817]],\n",
       "  \n",
       "                      [[-0.00287368,  0.00752242, -0.015355  , ...,\n",
       "                        -0.01603868, -0.02653095, -0.0164813 ],\n",
       "                       [-0.00633312, -0.00233079,  0.00837325, ...,\n",
       "                         0.00039684, -0.00798118,  0.02843736],\n",
       "                       [ 0.00120777,  0.00238825, -0.0048663 , ...,\n",
       "                         0.01041369,  0.01255398, -0.01398253],\n",
       "                       ...,\n",
       "                       [ 0.01471611, -0.01515   , -0.0005235 , ...,\n",
       "                        -0.01278221, -0.01074722, -0.02869743],\n",
       "                       [-0.01517044, -0.02141999,  0.00241291, ...,\n",
       "                         0.00734467, -0.00368588,  0.03233207],\n",
       "                       [ 0.00961553, -0.00894184, -0.0071127 , ...,\n",
       "                         0.0244472 ,  0.01411296,  0.00013923]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.00017607,  0.00051102,  0.00046666, ...,\n",
       "                        0.00071841,  0.0001173 , -0.00073035],\n",
       "                      [ 0.00064031,  0.00048266, -0.00037009, ...,\n",
       "                       -0.00028814, -0.00040784,  0.00062585]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-0.01315531,  0.00929612,  0.01268667, ...,\n",
       "                         0.01567291, -0.0169398 ,  0.0044371 ],\n",
       "                       [ 0.02195688, -0.01248089,  0.01370571, ...,\n",
       "                         0.02123559, -0.00429227,  0.00197526],\n",
       "                       [ 0.00579089, -0.0342161 , -0.01559996, ...,\n",
       "                         0.02096878,  0.01729412, -0.02702456],\n",
       "                       ...,\n",
       "                       [ 0.00818316, -0.00971073, -0.00638468, ...,\n",
       "                         0.00879319,  0.03109316, -0.00031673],\n",
       "                       [ 0.01180645,  0.00241796,  0.01060481, ...,\n",
       "                        -0.02573522, -0.01312182,  0.01609759],\n",
       "                       [-0.02814428,  0.00431215,  0.02456698, ...,\n",
       "                        -0.02204195, -0.02298194, -0.00594776]],\n",
       "  \n",
       "                      [[ 0.02572076, -0.00664863,  0.01773907, ...,\n",
       "                        -0.00421651, -0.02529038,  0.00763377],\n",
       "                       [ 0.02075639,  0.03208849, -0.02065718, ...,\n",
       "                         0.02991278,  0.03237514, -0.01549101],\n",
       "                       [ 0.0134667 , -0.01093371,  0.01503881, ...,\n",
       "                         0.01947693, -0.01301255,  0.00207962],\n",
       "                       ...,\n",
       "                       [-0.00931644,  0.03446814,  0.00999651, ...,\n",
       "                         0.02417099,  0.0035091 ,  0.03145451],\n",
       "                       [-0.0117931 , -0.00156472, -0.00949953, ...,\n",
       "                        -0.00620057,  0.01335385,  0.00272781],\n",
       "                       [-0.01300806, -0.00293265, -0.02126442, ...,\n",
       "                         0.02228271, -0.02045489, -0.01241421]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00060929,  0.00051023,  0.00049787, ...,\n",
       "                       -0.00055551, -0.00056919,  0.00051747],\n",
       "                      [-0.00060929,  0.00051023,  0.00049787, ...,\n",
       "                       -0.00055551, -0.00056919,  0.00051747]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.0029489 ,  0.00197105, -0.00921744, ...,\n",
       "                        -0.02100677, -0.00350567,  0.00904733],\n",
       "                       [ 0.02088315, -0.00591431,  0.03555607, ...,\n",
       "                         0.00146738,  0.00787466, -0.00187481],\n",
       "                       [-0.02120307, -0.00054205,  0.00757339, ...,\n",
       "                        -0.01824998,  0.02893102, -0.01280597],\n",
       "                       ...,\n",
       "                       [-0.01951291, -0.03125233, -0.0135967 , ...,\n",
       "                         0.02896759,  0.01688223, -0.01934421],\n",
       "                       [ 0.0011668 ,  0.02770017, -0.00787974, ...,\n",
       "                         0.01820824,  0.01131605, -0.00768364],\n",
       "                       [-0.01522528, -0.0175948 ,  0.02964117, ...,\n",
       "                         0.012181  ,  0.00112667, -0.0006677 ]],\n",
       "  \n",
       "                      [[-0.0223192 ,  0.01685362,  0.02589878, ...,\n",
       "                        -0.01363695,  0.00508482, -0.0129201 ],\n",
       "                       [-0.01070694,  0.01076161, -0.02878546, ...,\n",
       "                        -0.01195459, -0.0004394 , -0.00363508],\n",
       "                       [-0.00666345, -0.02082913,  0.00067982, ...,\n",
       "                         0.02303146,  0.0106234 ,  0.00355093],\n",
       "                       ...,\n",
       "                       [-0.02019636,  0.00672016,  0.00949724, ...,\n",
       "                         0.01864969,  0.00399669, -0.01672583],\n",
       "                       [ 0.0035138 , -0.00431917,  0.02658431, ...,\n",
       "                        -0.01294449, -0.02453605, -0.01365034],\n",
       "                       [-0.00011041, -0.01933054,  0.03420908, ...,\n",
       "                         0.01178807,  0.00812258, -0.01576776]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00037827,  0.00036862,  0.0006696 , ...,\n",
       "                       -0.00060339, -0.00065846,  0.00057371],\n",
       "                      [-0.00052228,  0.00073524,  0.00045338, ...,\n",
       "                       -0.00020019, -0.00058573,  0.00049547]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[0.9994899 , 0.99973464, 1.0004992 , ..., 1.0007927 ,\n",
       "                       0.9999131 , 0.99962103],\n",
       "                      [1.0000217 , 1.0007824 , 1.0007379 , ..., 1.0007335 ,\n",
       "                       0.99972427, 0.9993662 ]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.00275338, -0.02645631,  0.00899837, ...,\n",
       "                         0.00012249, -0.02805008,  0.00563955],\n",
       "                       [ 0.01549672,  0.00024256,  0.01212187, ...,\n",
       "                        -0.02287605,  0.01108136,  0.00467106],\n",
       "                       [ 0.00349135, -0.01286263,  0.0117798 , ...,\n",
       "                        -0.00296157,  0.00717812, -0.03271856],\n",
       "                       ...,\n",
       "                       [ 0.00770554,  0.03079321, -0.01444281, ...,\n",
       "                         0.0340772 ,  0.01762282,  0.00803766],\n",
       "                       [-0.01442973, -0.002825  ,  0.00152267, ...,\n",
       "                         0.00550893, -0.02329342,  0.01772897],\n",
       "                       [ 0.01110971, -0.01253105, -0.00611307, ...,\n",
       "                        -0.01070413, -0.01544889, -0.02384934]],\n",
       "  \n",
       "                      [[-0.02160651, -0.00822565, -0.00153619, ...,\n",
       "                        -0.01172809,  0.02608387,  0.01453248],\n",
       "                       [ 0.00470166, -0.01322582, -0.00470826, ...,\n",
       "                         0.0011184 , -0.02897632,  0.01273701],\n",
       "                       [-0.00382303,  0.00081727,  0.00074654, ...,\n",
       "                         0.01241096,  0.00808927,  0.00115746],\n",
       "                       ...,\n",
       "                       [ 0.03164303, -0.01097279, -0.00996539, ...,\n",
       "                         0.00833221, -0.00852347, -0.00289296],\n",
       "                       [ 0.00860185, -0.01094596,  0.03256889, ...,\n",
       "                        -0.03307224, -0.00024375, -0.03393432],\n",
       "                       [-0.0145752 ,  0.0041784 , -0.01786549, ...,\n",
       "                        -0.00117003, -0.01006613,  0.0091512 ]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.01859334,  0.00180483, -0.00604143, ...,\n",
       "                         0.01563159,  0.02538243,  0.01994409],\n",
       "                       [ 0.01698447,  0.00381177,  0.02130897, ...,\n",
       "                        -0.00704564, -0.00801096,  0.00377293],\n",
       "                       [-0.01797722, -0.02619647,  0.00037157, ...,\n",
       "                         0.00839816, -0.00883492,  0.00907284],\n",
       "                       ...,\n",
       "                       [ 0.0169149 ,  0.02343033,  0.00031186, ...,\n",
       "                        -0.01737709, -0.02696689,  0.01092947],\n",
       "                       [-0.03060185,  0.01043943, -0.00801739, ...,\n",
       "                         0.00233425,  0.00766407,  0.0051832 ],\n",
       "                       [ 0.02181858, -0.00758729,  0.00269534, ...,\n",
       "                        -0.01771193,  0.00615032,  0.01472577]],\n",
       "  \n",
       "                      [[ 0.00355791,  0.0086803 , -0.00495735, ...,\n",
       "                         0.00914166, -0.00476304, -0.00508665],\n",
       "                       [-0.0123701 , -0.02872241,  0.02719282, ...,\n",
       "                        -0.00980733, -0.00826514,  0.00309539],\n",
       "                       [-0.01452856,  0.00732416,  0.00065597, ...,\n",
       "                        -0.00036039,  0.01090192, -0.00746353],\n",
       "                       ...,\n",
       "                       [ 0.0116548 ,  0.02342798,  0.01623347, ...,\n",
       "                         0.01224666,  0.00090082,  0.00427436],\n",
       "                       [-0.01095233, -0.0085678 ,  0.03127319, ...,\n",
       "                        -0.00624725, -0.00349983, -0.02341755],\n",
       "                       [-0.00611948, -0.00678349, -0.01644673, ...,\n",
       "                        -0.01851318,  0.01832537,  0.00097025]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 1.47990538e-02,  9.10216104e-03,  3.20515339e-03,\n",
       "                        ...,  6.96957996e-03, -1.29472325e-02,\n",
       "                         2.98446268e-02],\n",
       "                       [ 2.96188332e-02, -2.26269616e-03, -2.06205938e-02,\n",
       "                        ..., -3.12029105e-02, -9.89959296e-03,\n",
       "                        -3.06427628e-02],\n",
       "                       [-3.39588188e-02,  9.24647972e-03, -1.53506231e-02,\n",
       "                        ..., -7.54033914e-03,  6.22487115e-03,\n",
       "                        -2.60439869e-02],\n",
       "                       ...,\n",
       "                       [ 1.40722990e-02,  1.03122555e-02, -1.21679753e-02,\n",
       "                        ...,  6.14862610e-03, -2.42020264e-02,\n",
       "                         1.28329266e-02],\n",
       "                       [ 7.17481365e-03, -1.55059632e-03, -7.80874258e-03,\n",
       "                        ...,  1.11822300e-02,  6.92657428e-03,\n",
       "                        -4.47076885e-03],\n",
       "                       [-1.00411922e-02,  7.75359897e-03, -1.76014546e-02,\n",
       "                        ..., -2.06665508e-03, -3.85943218e-03,\n",
       "                         2.67860503e-03]],\n",
       "  \n",
       "                      [[ 3.52777131e-02,  2.33818665e-02, -2.74143424e-02,\n",
       "                        ...,  9.37616732e-03,  3.67319724e-03,\n",
       "                         2.27178005e-03],\n",
       "                       [ 2.86059063e-02,  2.86900792e-02,  3.30193825e-02,\n",
       "                        ...,  4.56468115e-06,  3.21940682e-03,\n",
       "                        -3.65056167e-03],\n",
       "                       [-1.83168072e-02, -5.69619564e-03, -1.54271899e-02,\n",
       "                        ..., -7.43460609e-03, -5.54785412e-03,\n",
       "                        -3.40310968e-02],\n",
       "                       ...,\n",
       "                       [ 8.16958956e-03, -8.41602404e-03,  2.50740070e-02,\n",
       "                        ..., -2.67431363e-02,  1.14166662e-02,\n",
       "                        -2.50997464e-03],\n",
       "                       [ 5.35695523e-04, -3.99564113e-03, -3.20574245e-03,\n",
       "                        ..., -7.33594643e-03,  3.61190028e-02,\n",
       "                         5.92947984e-03],\n",
       "                       [-3.59523878e-03,  2.69354042e-02,  3.28698382e-02,\n",
       "                        ...,  3.55450325e-02, -7.92625174e-03,\n",
       "                        -6.04891963e-03]]], dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.00296886,  0.0039933 ,  0.00675254, ...,\n",
       "                        -0.03345044, -0.00885641,  0.00861499],\n",
       "                       [-0.01159763, -0.02911669, -0.00249723, ...,\n",
       "                         0.02188332, -0.00142649, -0.00011364],\n",
       "                       [ 0.00955645, -0.00576795, -0.00053527, ...,\n",
       "                         0.00775755, -0.00423187,  0.00156254],\n",
       "                       ...,\n",
       "                       [ 0.01443788,  0.01405801,  0.00682346, ...,\n",
       "                         0.01289551,  0.00092803,  0.00879647],\n",
       "                       [-0.00876141,  0.01416521,  0.00381647, ...,\n",
       "                        -0.00187065,  0.01900627, -0.00746261],\n",
       "                       [ 0.01792601,  0.00785812, -0.01676667, ...,\n",
       "                        -0.01577426, -0.01354182, -0.00186234]],\n",
       "  \n",
       "                      [[-0.00197409, -0.00462081,  0.00921937, ...,\n",
       "                        -0.00558336,  0.02454845,  0.03434126],\n",
       "                       [-0.03222016, -0.0181143 ,  0.00841099, ...,\n",
       "                         0.0258846 ,  0.00860624, -0.00560274],\n",
       "                       [ 0.01259127, -0.00446824, -0.02455385, ...,\n",
       "                         0.02420026, -0.01705331,  0.00791773],\n",
       "                       ...,\n",
       "                       [ 0.00528716,  0.01052587,  0.0144986 , ...,\n",
       "                         0.00247511, -0.0249603 , -0.01951431],\n",
       "                       [-0.0072859 ,  0.02830923,  0.00323052, ...,\n",
       "                        -0.01658189, -0.00085755, -0.00491144],\n",
       "                       [-0.005269  , -0.01900203,  0.011558  , ...,\n",
       "                         0.00354869, -0.02622661,  0.01116688]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[ 7.6534378e-04,  8.0186565e-04, -2.5630798e-04, ...,\n",
       "                        7.4096536e-04,  3.5274486e-04,  7.3907257e-04],\n",
       "                      [-4.6968472e-04,  6.7406642e-04,  6.7347672e-04, ...,\n",
       "                       -2.0850210e-05,  6.3182879e-04,  2.8453322e-04]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.01612641, -0.03642456,  0.01320156, ...,\n",
       "                        -0.01591277, -0.00697433,  0.02355153],\n",
       "                       [ 0.00780502,  0.01153156, -0.02087019, ...,\n",
       "                         0.01615742,  0.02576369,  0.00589431],\n",
       "                       [ 0.00042169, -0.0041694 , -0.01705889, ...,\n",
       "                        -0.00232322, -0.00850033, -0.00504524],\n",
       "                       ...,\n",
       "                       [-0.00334712,  0.01100082, -0.02410891, ...,\n",
       "                        -0.02614756, -0.0204379 ,  0.00746757],\n",
       "                       [ 0.02551928, -0.00187518,  0.02420117, ...,\n",
       "                         0.02105018,  0.00558836,  0.02683115],\n",
       "                       [ 0.00043127, -0.00445538, -0.01863175, ...,\n",
       "                        -0.03091845,  0.02033989, -0.00505317]],\n",
       "  \n",
       "                      [[ 0.00713779, -0.0210742 ,  0.03023325, ...,\n",
       "                        -0.00123097, -0.03383307, -0.03132044],\n",
       "                       [ 0.03037526, -0.01793361, -0.00876775, ...,\n",
       "                         0.00453467,  0.00418678,  0.02654137],\n",
       "                       [ 0.00855299, -0.01619878,  0.00210091, ...,\n",
       "                         0.01582392, -0.00275333,  0.0104252 ],\n",
       "                       ...,\n",
       "                       [-0.00404753, -0.0048815 ,  0.01283732, ...,\n",
       "                         0.00404955,  0.01682056, -0.01076421],\n",
       "                       [-0.00735649, -0.02104711, -0.01794319, ...,\n",
       "                        -0.00875743,  0.00201775, -0.02234603],\n",
       "                       [-0.01789191,  0.01929509,  0.00419141, ...,\n",
       "                         0.01100844,  0.00168086,  0.01785192]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-0.00062802,  0.00029306,  0.00042564, ...,\n",
       "                       -0.00061725, -0.00055433,  0.00054442],\n",
       "                      [-0.00062802,  0.00029306,  0.00042564, ...,\n",
       "                       -0.00061725, -0.00055433,  0.00054442]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[-0.00024362,  0.00801965, -0.00630777, ...,\n",
       "                         0.01547269, -0.03024147, -0.02285569],\n",
       "                       [ 0.02322815,  0.01640048, -0.02252694, ...,\n",
       "                        -0.00377768,  0.00323462, -0.01345607],\n",
       "                       [ 0.01003059, -0.02697166, -0.02978192, ...,\n",
       "                         0.00302598, -0.00126103, -0.00479842],\n",
       "                       ...,\n",
       "                       [ 0.00633349, -0.01097174,  0.00902128, ...,\n",
       "                        -0.0129189 , -0.01683971,  0.00333436],\n",
       "                       [-0.01372411, -0.00660935,  0.01173951, ...,\n",
       "                         0.00264712,  0.00909979,  0.03338987],\n",
       "                       [-0.00103675,  0.00766624, -0.0103504 , ...,\n",
       "                        -0.00985823, -0.03011905, -0.01201455]],\n",
       "  \n",
       "                      [[ 0.03143562,  0.02907672,  0.0045831 , ...,\n",
       "                        -0.00313562, -0.00732794, -0.02238746],\n",
       "                       [ 0.00901275,  0.03482956,  0.00469147, ...,\n",
       "                        -0.00010705, -0.0039764 ,  0.00553864],\n",
       "                       [-0.00282237, -0.01007119,  0.01764287, ...,\n",
       "                        -0.02821987,  0.00175292,  0.01511307],\n",
       "                       ...,\n",
       "                       [-0.00956375,  0.00814112, -0.02223618, ...,\n",
       "                        -0.00544001,  0.01649397,  0.01703755],\n",
       "                       [ 0.01822298,  0.02202316,  0.02173186, ...,\n",
       "                         0.0146193 ,  0.00917864,  0.00629569],\n",
       "                       [-0.02327736, -0.01482764,  0.02002177, ...,\n",
       "                        -0.01619598, -0.01103428,  0.00449908]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[-7.4065349e-04,  8.1299117e-04,  7.6022750e-04, ...,\n",
       "                       -7.1259571e-04, -6.7899533e-04,  6.7933620e-04],\n",
       "                      [ 8.6651460e-05,  7.4803334e-04, -5.3558371e-04, ...,\n",
       "                        6.9046876e-04, -6.7415438e-04,  7.3131837e-04]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[1.0001335, 1.0007672, 1.0004752, ..., 1.0007817,\n",
       "                       1.0003952, 1.0003653],\n",
       "                      [0.9992639, 0.9995753, 0.9993244, ..., 0.9992546,\n",
       "                       0.9993058, 0.9995578]], dtype=float32),\n",
       "  ShardedDeviceArray([[ 0.00076794,  0.00081761,  0.00075719, ...,\n",
       "                       -0.00073728, -0.00073066, -0.00069947],\n",
       "                      [-0.00075298, -0.00071726, -0.00075115, ...,\n",
       "                       -0.00073992, -0.00073196, -0.00074018]],                   dtype=float32),\n",
       "  ShardedDeviceArray([[[ 0.01413697, -0.00271157, -0.00305449, ...,\n",
       "                        -0.00281658,  0.01381677, -0.0024512 ],\n",
       "                       [-0.00743758, -0.00350862, -0.01701293, ...,\n",
       "                        -0.00032132, -0.02486724, -0.00971462],\n",
       "                       [ 0.02191363,  0.0333645 , -0.0172399 , ...,\n",
       "                        -0.02882694, -0.00377304,  0.00391429],\n",
       "                       ...,\n",
       "                       [ 0.02616718, -0.03126368, -0.01455668, ...,\n",
       "                        -0.00529224,  0.00252227,  0.00567326],\n",
       "                       [ 0.00131212,  0.00389918,  0.02065752, ...,\n",
       "                         0.0039371 , -0.01017992, -0.00992921],\n",
       "                       [ 0.03067342, -0.00080562,  0.00971792, ...,\n",
       "                        -0.00521002, -0.00235926, -0.03137142]],\n",
       "  \n",
       "                      [[-0.03384893,  0.0280563 ,  0.00803875, ...,\n",
       "                         0.00232335, -0.01802211,  0.01163805],\n",
       "                       [-0.00749265, -0.00476589,  0.03519015, ...,\n",
       "                         0.01601272,  0.0055809 ,  0.01548906],\n",
       "                       [ 0.01379387,  0.02488856, -0.00531083, ...,\n",
       "                        -0.00034661, -0.00644346,  0.0093032 ],\n",
       "                       ...,\n",
       "                       [ 0.01329416,  0.02882426,  0.00167776, ...,\n",
       "                        -0.02335364,  0.00558498,  0.00696596],\n",
       "                       [ 0.00276791, -0.00715332, -0.0300235 , ...,\n",
       "                        -0.01131061, -0.0174912 ,  0.01420881],\n",
       "                       [ 0.00632075,  0.01982101, -0.03596598, ...,\n",
       "                        -0.02747365, -0.00100396,  0.01864637]]],                   dtype=float32),\n",
       "  ShardedDeviceArray([9, 9], dtype=int32)],\n",
       " PyTreeDef({'opt_state': (CustomNode(namedtuple[<class 'optax._src.transform.ScaleByAdamState'>], [*, CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'causal_transformer_shard/~/embedding_shard': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'pos_embs': *})], [*]), 'causal_transformer_shard/~/embedding_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *])})], [*, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *]), CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'causal_transformer_shard/~/embedding_shard': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'pos_embs': *})], [*]), 'causal_transformer_shard/~/embedding_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *])})], [*, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *])]), CustomNode(namedtuple[<class 'optax._src.base.EmptyState'>], [])), 'params': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'causal_transformer_shard/~/embedding_shard': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'pos_embs': *})], [*]), 'causal_transformer_shard/~/embedding_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_0/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_0/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_1': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_2': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_3': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'w': *})], [*]), 'causal_transformer_shard/~/layer_1/~/linear_4': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/layer_1/~/linear_5': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/layer_norm': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'offset': *, 'scale': *})], [*, *]), 'causal_transformer_shard/~/projection_shard/~/linear': CustomNode(<class 'haiku._src.data_structures.FlatMap'>[PyTreeDef({'b': *, 'w': *})], [*, *])})], [*, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *, *]), 'step': *}))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_flatten(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mMain binary filename not available.\r",
      "\r\n",
      "\u001b[0m device: Total 12.4GB\r\n",
      "         1.9GB (15.14%): TPU_0(process=0,(0,0,0,0))\r\n",
      "         1.5GB (12.12%): TPU_1(process=0,(0,0,0,1))\r\n",
      "         1.5GB (12.12%): TPU_2(process=0,(1,0,0,0))\r\n",
      "         1.5GB (12.12%): TPU_3(process=0,(1,0,0,1))\r\n",
      "         1.5GB (12.12%): TPU_4(process=0,(0,1,0,0))\r\n",
      "         1.5GB (12.12%): TPU_5(process=0,(0,1,0,1))\r\n",
      "         1.5GB (12.12%): TPU_6(process=0,(1,1,0,0))\r\n",
      "         1.5GB (12.12%): TPU_7(process=0,(1,1,0,1))\r\n",
      "\r\n",
      " kind: Total 12.4GB\r\n",
      "         12.4GB (  100%): buffer\r\n",
      "       -55.0B (4.1e-07%): executable\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "show_mem(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ckpt_dir: str, state) -> None:\n",
    "    with open(os.path.join(ckpt_dir, \"arrays.npy\"), \"wb\") as f:\n",
    "        for x in jax.tree_leaves(state):\n",
    "            np.save(f, x, allow_pickle=False)\n",
    "\n",
    "    tree_struct = jax.tree_map(lambda t: 0, state)\n",
    "    with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(tree_struct, f)\n",
    "\n",
    "def restore(ckpt_dir):\n",
    "    with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"rb\") as f:\n",
    "        tree_struct = pickle.load(f)\n",
    " \n",
    "    leaves, treedef = jax.tree_flatten(tree_struct)\n",
    "    with open(os.path.join(ckpt_dir, \"arrays.npy\"), \"rb\") as f:\n",
    "        flat_state = [np.load(f) for _ in leaves]\n",
    "\n",
    "    return jax.tree_unflatten(treedef, flat_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save('model', state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = restore('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf \n",
    "d = tfds.load(name='tiny_shakespeare')['train']\n",
    "d = d.map(lambda x: tf.strings.unicode_split(x['text'], 'UTF-8'))\n",
    "# train split includes vocabulary for other splits\n",
    "vocabulary = sorted(set(next(iter(d)).numpy()))\n",
    "d = d.map(lambda x: {'cur_char': x[:-1], 'next_char': x[1:]})\n",
    "d = d.unbatch()\n",
    "seq_len = 100\n",
    "batch_size = 2\n",
    "d = d.batch(seq_len)\n",
    "d = d.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cur_char': <tf.Tensor: shape=(2, 100), dtype=string, numpy=\n",
       " array([[b'F', b'i', b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z',\n",
       "         b'e', b'n', b':', b'\\n', b'B', b'e', b'f', b'o', b'r', b'e',\n",
       "         b' ', b'w', b'e', b' ', b'p', b'r', b'o', b'c', b'e', b'e', b'd',\n",
       "         b' ', b'a', b'n', b'y', b' ', b'f', b'u', b'r', b't', b'h', b'e',\n",
       "         b'r', b',', b' ', b'h', b'e', b'a', b'r', b' ', b'm', b'e', b' ',\n",
       "         b's', b'p', b'e', b'a', b'k', b'.', b'\\n', b'\\n', b'A', b'l',\n",
       "         b'l', b':', b'\\n', b'S', b'p', b'e', b'a', b'k', b',', b' ',\n",
       "         b's', b'p', b'e', b'a', b'k', b'.', b'\\n', b'\\n', b'F', b'i',\n",
       "         b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z', b'e', b'n',\n",
       "         b':', b'\\n', b'Y', b'o', b'u'],\n",
       "        [b' ', b'a', b'r', b'e', b' ', b'a', b'l', b'l', b' ', b'r', b'e',\n",
       "         b's', b'o', b'l', b'v', b'e', b'd', b' ', b'r', b'a', b't', b'h',\n",
       "         b'e', b'r', b' ', b't', b'o', b' ', b'd', b'i', b'e', b' ', b't',\n",
       "         b'h', b'a', b'n', b' ', b't', b'o', b' ', b'f', b'a', b'm', b'i',\n",
       "         b's', b'h', b'?', b'\\n', b'\\n', b'A', b'l', b'l', b':', b'\\n',\n",
       "         b'R', b'e', b's', b'o', b'l', b'v', b'e', b'd', b'.', b' ', b'r',\n",
       "         b'e', b's', b'o', b'l', b'v', b'e', b'd', b'.', b'\\n', b'\\n',\n",
       "         b'F', b'i', b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z',\n",
       "         b'e', b'n', b':', b'\\n', b'F', b'i', b'r', b's', b't', b',',\n",
       "         b' ', b'y', b'o', b'u']], dtype=object)>,\n",
       " 'next_char': <tf.Tensor: shape=(2, 100), dtype=string, numpy=\n",
       " array([[b'i', b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z', b'e',\n",
       "         b'n', b':', b'\\n', b'B', b'e', b'f', b'o', b'r', b'e', b' ',\n",
       "         b'w', b'e', b' ', b'p', b'r', b'o', b'c', b'e', b'e', b'd', b' ',\n",
       "         b'a', b'n', b'y', b' ', b'f', b'u', b'r', b't', b'h', b'e', b'r',\n",
       "         b',', b' ', b'h', b'e', b'a', b'r', b' ', b'm', b'e', b' ', b's',\n",
       "         b'p', b'e', b'a', b'k', b'.', b'\\n', b'\\n', b'A', b'l', b'l',\n",
       "         b':', b'\\n', b'S', b'p', b'e', b'a', b'k', b',', b' ', b's',\n",
       "         b'p', b'e', b'a', b'k', b'.', b'\\n', b'\\n', b'F', b'i', b'r',\n",
       "         b's', b't', b' ', b'C', b'i', b't', b'i', b'z', b'e', b'n', b':',\n",
       "         b'\\n', b'Y', b'o', b'u', b' '],\n",
       "        [b'a', b'r', b'e', b' ', b'a', b'l', b'l', b' ', b'r', b'e', b's',\n",
       "         b'o', b'l', b'v', b'e', b'd', b' ', b'r', b'a', b't', b'h', b'e',\n",
       "         b'r', b' ', b't', b'o', b' ', b'd', b'i', b'e', b' ', b't', b'h',\n",
       "         b'a', b'n', b' ', b't', b'o', b' ', b'f', b'a', b'm', b'i', b's',\n",
       "         b'h', b'?', b'\\n', b'\\n', b'A', b'l', b'l', b':', b'\\n', b'R',\n",
       "         b'e', b's', b'o', b'l', b'v', b'e', b'd', b'.', b' ', b'r', b'e',\n",
       "         b's', b'o', b'l', b'v', b'e', b'd', b'.', b'\\n', b'\\n', b'F',\n",
       "         b'i', b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z', b'e',\n",
       "         b'n', b':', b'\\n', b'F', b'i', b'r', b's', b't', b',', b' ',\n",
       "         b'y', b'o', b'u', b' ']], dtype=object)>}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(d).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.19.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/sholto/.local/lib/python3.8/site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/lib/python3/dist-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.18.2)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (3.17.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.12.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.5.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.4)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=fabf86e4b611845bc55ac1f31504689a55f73217ff7db2d85acc3bacffc3baaf\n",
      "  Stored in directory: /home/sholto/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built promise\n",
      "Installing collected packages: zipp, tensorflow-metadata, promise, importlib-resources, dill, tensorflow-datasets\n",
      "Successfully installed dill-0.3.4 importlib-resources-5.4.0 promise-2.3 tensorflow-datasets-4.4.0 tensorflow-metadata-1.5.0 zipp-3.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.process_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "init = jax.experimental.maps.xmap(hk.transform(model_fn).init, \n",
    "                                  in_axes=([\"shard\", ...],\n",
    "                                          [\"batch\", ...]),\n",
    "                                  out_axes=[\"shard\", ...],\n",
    "                                  axis_resources={'shard':'shard', 'batch':'batch'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = hk.PRNGSequence(42)\n",
    "\n",
    "x = jax.random.uniform(next(key), (16, 32, 768), minval=0, maxval=255).astype(jnp.float32)  # batch, len\n",
    "\n",
    "state = hk.transform(model_fn).init(jnp.array(next(key)), x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute the mean on each device in parallel and print the results\n",
    "per_device_mean = pmap(jnp.mean)(result)\n",
    "collective_mean = jnp.mean(per_device_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        self.train_xmap = jax.experimental.maps.xmap(fun=train,\n",
    "                                                     in_axes=([\"shard\", ...],\n",
    "                                                              [\"batch\", ...],\n",
    "                                                              [\"batch\", ...]),\n",
    "                                                     out_axes=([\"batch\", ...], [\"batch\", ...], [\"batch\", ...], [\"batch\", ...], [\"shard\", ...]),\n",
    "                                                     donate_argnums=(0,),\n",
    "                                                     axis_resources={'shard': 'mp', 'batch': 'dp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [12.8, 40.96, 51.2, 64.0,128, 512]\n",
    "y = [14.2, 58.6, 80.1, 109.9, 314, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6400 * 6400 * 4 / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from jax import grad, jit\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import resource\n",
    "\n",
    "class F:\n",
    "    def __init__(self):\n",
    "        self.A = np.ones((1000000, 100))\n",
    "        self.A = jnp.asarray(self.A)\n",
    "        self._gr = jit(grad(self._fn))\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def _fn(self, x, A):\n",
    "        y = jnp.dot(A, x)\n",
    "        return jnp.sum(y)\n",
    "    def fn(self, x):\n",
    "        return self._fn(x, self.A)\n",
    "    def gr(self, x):\n",
    "        return self._gr(x, self.A)\n",
    "\n",
    "rss_mb = lambda: resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024\n",
    "init = rss_mb()\n",
    "\n",
    "objF = F()\n",
    "x = np.ones(100)\n",
    "x = jnp.asarray(x)\n",
    "y = objF.fn(x).block_until_ready()\n",
    "\n",
    "print(\"Before grad\")\n",
    "print(f\"RSS: {rss_mb() - init:.2f}MB\")\n",
    "\n",
    "z = objF.gr(x).block_until_ready()\n",
    "\n",
    "print(\"After grad\")\n",
    "print(f\"RSS: {rss_mb() - init:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.profiler\n",
    "\n",
    "def func1(x):\n",
    "  return jnp.tile(x, 10) * 0.5\n",
    "\n",
    "def func2(x):\n",
    "  y = func1(x)\n",
    "  return y, jnp.tile(x, 10) + 1\n",
    "\n",
    "x = jax.random.normal(jax.random.PRNGKey(42), (10000, 1000))\n",
    "y, z = func2(x)\n",
    "\n",
    "z.block_until_ready()\n",
    "\n",
    "jax.profiler.save_device_memory_profile(\"memory.prof\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = pmap(lambda x: x ** 2)(jnp.arange(7))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_variables(): \n",
    "    for name in dir():\n",
    "        if not name.startswith('_'):\n",
    "            del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a bunch of CPU devices.\n",
    "def setUpModule():\n",
    "    global prev_xla_flags\n",
    "    prev_xla_flags = os.getenv(\"XLA_FLAGS\")\n",
    "    flags_str = prev_xla_flags or \"\"\n",
    "    if \"xla_force_host_platform_device_count\" not in flags_str:\n",
    "        os.environ[\"XLA_FLAGS\"] = (flags_str + \" --xla_force_host_platform_device_count=16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
